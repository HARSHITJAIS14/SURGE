{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-12T00:20:19.214060Z",
     "iopub.status.busy": "2025-06-12T00:20:19.213829Z",
     "iopub.status.idle": "2025-06-12T00:20:20.968057Z",
     "shell.execute_reply": "2025-06-12T00:20:20.967305Z",
     "shell.execute_reply.started": "2025-06-12T00:20:19.214042Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/raid-dataset/extra.csv\n",
      "/kaggle/input/raid-dataset/train.csv\n",
      "/kaggle/input/raid-dataset/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:20:20.969582Z",
     "iopub.status.busy": "2025-06-12T00:20:20.969191Z",
     "iopub.status.idle": "2025-06-12T00:24:49.877820Z",
     "shell.execute_reply": "2025-06-12T00:24:49.877113Z",
     "shell.execute_reply.started": "2025-06-12T00:20:20.969562Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 11)\n",
      "model\n",
      "gpt4     5000\n",
      "human    5000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load the CSV\n",
    "df = pd.read_csv('/kaggle/input/raid-dataset/train.csv')\n",
    "\n",
    "# 2. Filter for human and GPT-4 rows\n",
    "#    (replace 'model' with whatever your column is called)\n",
    "df_human = df[df['model'] == 'human']\n",
    "df_gpt4  = df[df['model'] == 'gpt4']\n",
    "\n",
    "# 3. Sample 5000 from each (if you only need up to 5000, use min count)\n",
    "n = 5000\n",
    "df_human_samp = df_human.sample(n=min(n, len(df_human)), random_state=42)\n",
    "df_gpt4_samp  = df_gpt4.sample(n=min(n, len(df_gpt4)),   random_state=42)\n",
    "\n",
    "# 4. Combine and shuffle\n",
    "df_sample = pd.concat([df_human_samp, df_gpt4_samp]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(df_sample.shape)   # should be (10000, …)\n",
    "print(df_sample['model'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:28:31.178052Z",
     "iopub.status.busy": "2025-06-12T00:28:31.177274Z",
     "iopub.status.idle": "2025-06-12T00:28:32.538622Z",
     "shell.execute_reply": "2025-06-12T00:28:32.537775Z",
     "shell.execute_reply.started": "2025-06-12T00:28:31.178026Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 11)\n",
      "model\n",
      "human      20000\n",
      "gpt4       20000\n",
      "chatgpt    20000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 2. Filter for human and GPT-4 rows\n",
    "#    (replace 'model' with whatever your column is called)\n",
    "df_human = df[df['model'] == 'human']\n",
    "df_gpt4  = df[df['model'] == 'gpt4']\n",
    "df_chatgpt=df[df['model'] == 'chatgpt']\n",
    "\n",
    "# 3. Sample 5000 from each (if you only need up to 5000, use min count)\n",
    "\n",
    "df_human_samp = df_human.sample(n=min(20000, len(df_human)), random_state=42)\n",
    "df_gpt4_samp  = df_gpt4.sample(n=min(20000, len(df_gpt4)),   random_state=42)\n",
    "df_chatgpt_samp  = df_chatgpt.sample(n=min(20000, len(df_chatgpt)),   random_state=42)\n",
    "\n",
    "# 4. Combine and shuffle\n",
    "df_sample = pd.concat([df_human_samp, df_gpt4_samp,df_chatgpt_samp]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(df_sample.shape)   # should be (10000, …)\n",
    "print(df_sample['model'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:28:56.525776Z",
     "iopub.status.busy": "2025-06-12T00:28:56.525265Z",
     "iopub.status.idle": "2025-06-12T00:29:00.261282Z",
     "shell.execute_reply": "2025-06-12T00:29:00.260640Z",
     "shell.execute_reply.started": "2025-06-12T00:28:56.525757Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 1) Save the sampled DataFrame to CSV\n",
    "df_sample.to_csv('sampled_train.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:30:02.806754Z",
     "iopub.status.busy": "2025-06-12T00:30:02.806163Z",
     "iopub.status.idle": "2025-06-12T00:30:05.722538Z",
     "shell.execute_reply": "2025-06-12T00:30:05.721997Z",
     "shell.execute_reply.started": "2025-06-12T00:30:02.806729Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"/kaggle/working/sampled_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:30:08.290340Z",
     "iopub.status.busy": "2025-06-12T00:30:08.290064Z",
     "iopub.status.idle": "2025-06-12T00:30:08.481052Z",
     "shell.execute_reply": "2025-06-12T00:30:08.480333Z",
     "shell.execute_reply.started": "2025-06-12T00:30:08.290318Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>adv_source_id</th>\n",
       "      <th>source_id</th>\n",
       "      <th>model</th>\n",
       "      <th>decoding</th>\n",
       "      <th>repetition_penalty</th>\n",
       "      <th>attack</th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>prompt</th>\n",
       "      <th>generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56a0eb85-8d33-4b7c-96b1-edde193e3536</td>\n",
       "      <td>9351499c-21fd-4d94-906f-28cc40a6fbab</td>\n",
       "      <td>9351499c-21fd-4d94-906f-28cc40a6fbab</td>\n",
       "      <td>human</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>number</td>\n",
       "      <td>reddit</td>\n",
       "      <td>My mom is shaming me for wanting to get off of...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I have been medicated for ADHD and anxiety for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>375ccfff-b83a-47a4-af50-d0c28e044f50</td>\n",
       "      <td>dbc75b18-0a96-47f5-b9d4-5e885f94dacb</td>\n",
       "      <td>ab5d1a0b-22a0-4933-9cb9-65026cd569b4</td>\n",
       "      <td>gpt4</td>\n",
       "      <td>greedy</td>\n",
       "      <td>no</td>\n",
       "      <td>insert_paragraphs</td>\n",
       "      <td>reddit</td>\n",
       "      <td>DAE feel like their dreams make up memories? A...</td>\n",
       "      <td>Write just the body of a Reddit post titled \"D...</td>\n",
       "      <td>I've been experiencing this strange phenomenon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90dce70c-1212-4e49-bd4b-9eee832048c0</td>\n",
       "      <td>d18cad56-11bf-4996-a22b-2b886c4bbef3</td>\n",
       "      <td>a48234f2-e5fb-471a-be2c-06500667b4e2</td>\n",
       "      <td>gpt4</td>\n",
       "      <td>sampling</td>\n",
       "      <td>no</td>\n",
       "      <td>article_deletion</td>\n",
       "      <td>news</td>\n",
       "      <td>FBI agent colludes with analyst</td>\n",
       "      <td>Write the body of a BBC news article titled \"F...</td>\n",
       "      <td>An FBI agent stands accused of colluding with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9e767500-0b0e-4e5b-9842-da4bf6812f75</td>\n",
       "      <td>757dc95e-18ef-4128-bcef-16028efe4202</td>\n",
       "      <td>757dc95e-18ef-4128-bcef-16028efe4202</td>\n",
       "      <td>human</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>insert_paragraphs</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>Towards the effectiveness of Deep Convolutiona...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Deep Learning is considered to be a quite youn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570ddd69-e566-44f3-a314-96475fe55eaa</td>\n",
       "      <td>5bfe05cb-02aa-44d5-8b31-f827a1e6ef04</td>\n",
       "      <td>5bfe05cb-02aa-44d5-8b31-f827a1e6ef04</td>\n",
       "      <td>human</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>number</td>\n",
       "      <td>books</td>\n",
       "      <td>Helen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Helen tells the story of a young orphan, Hele...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id                         adv_source_id  \\\n",
       "0  56a0eb85-8d33-4b7c-96b1-edde193e3536  9351499c-21fd-4d94-906f-28cc40a6fbab   \n",
       "1  375ccfff-b83a-47a4-af50-d0c28e044f50  dbc75b18-0a96-47f5-b9d4-5e885f94dacb   \n",
       "2  90dce70c-1212-4e49-bd4b-9eee832048c0  d18cad56-11bf-4996-a22b-2b886c4bbef3   \n",
       "3  9e767500-0b0e-4e5b-9842-da4bf6812f75  757dc95e-18ef-4128-bcef-16028efe4202   \n",
       "4  570ddd69-e566-44f3-a314-96475fe55eaa  5bfe05cb-02aa-44d5-8b31-f827a1e6ef04   \n",
       "\n",
       "                              source_id  model  decoding repetition_penalty  \\\n",
       "0  9351499c-21fd-4d94-906f-28cc40a6fbab  human       NaN                NaN   \n",
       "1  ab5d1a0b-22a0-4933-9cb9-65026cd569b4   gpt4    greedy                 no   \n",
       "2  a48234f2-e5fb-471a-be2c-06500667b4e2   gpt4  sampling                 no   \n",
       "3  757dc95e-18ef-4128-bcef-16028efe4202  human       NaN                NaN   \n",
       "4  5bfe05cb-02aa-44d5-8b31-f827a1e6ef04  human       NaN                NaN   \n",
       "\n",
       "              attack     domain  \\\n",
       "0             number     reddit   \n",
       "1  insert_paragraphs     reddit   \n",
       "2   article_deletion       news   \n",
       "3  insert_paragraphs  abstracts   \n",
       "4             number      books   \n",
       "\n",
       "                                               title  \\\n",
       "0  My mom is shaming me for wanting to get off of...   \n",
       "1  DAE feel like their dreams make up memories? A...   \n",
       "2                    FBI agent colludes with analyst   \n",
       "3  Towards the effectiveness of Deep Convolutiona...   \n",
       "4                                              Helen   \n",
       "\n",
       "                                              prompt  \\\n",
       "0                                                NaN   \n",
       "1  Write just the body of a Reddit post titled \"D...   \n",
       "2  Write the body of a BBC news article titled \"F...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                          generation  \n",
       "0  I have been medicated for ADHD and anxiety for...  \n",
       "1  I've been experiencing this strange phenomenon...  \n",
       "2  An FBI agent stands accused of colluding with ...  \n",
       "3  Deep Learning is considered to be a quite youn...  \n",
       "4   Helen tells the story of a young orphan, Hele...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:34:09.769021Z",
     "iopub.status.busy": "2025-06-12T00:34:09.768726Z",
     "iopub.status.idle": "2025-06-12T00:34:09.779695Z",
     "shell.execute_reply": "2025-06-12T00:34:09.779003Z",
     "shell.execute_reply.started": "2025-06-12T00:34:09.769000Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_main=df[[\"model\",\"title\",\"generation\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:34:48.109781Z",
     "iopub.status.busy": "2025-06-12T00:34:48.109312Z",
     "iopub.status.idle": "2025-06-12T00:34:48.179349Z",
     "shell.execute_reply": "2025-06-12T00:34:48.178602Z",
     "shell.execute_reply.started": "2025-06-12T00:34:48.109759Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35/3475066341.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_main[\"text\"]=df['title']+df['generation']\n"
     ]
    }
   ],
   "source": [
    "df_main[\"text\"]=df['title']+df['generation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:34:54.788437Z",
     "iopub.status.busy": "2025-06-12T00:34:54.787729Z",
     "iopub.status.idle": "2025-06-12T00:34:54.796336Z",
     "shell.execute_reply": "2025-06-12T00:34:54.795746Z",
     "shell.execute_reply.started": "2025-06-12T00:34:54.788404Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>title</th>\n",
       "      <th>generation</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>My mom is shaming me for wanting to get off of...</td>\n",
       "      <td>I have been medicated for ADHD and anxiety for...</td>\n",
       "      <td>My mom is shaming me for wanting to get off of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>DAE feel like their dreams make up memories? A...</td>\n",
       "      <td>I've been experiencing this strange phenomenon...</td>\n",
       "      <td>DAE feel like their dreams make up memories? A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>FBI agent colludes with analyst</td>\n",
       "      <td>An FBI agent stands accused of colluding with ...</td>\n",
       "      <td>FBI agent colludes with analystAn FBI agent st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>human</td>\n",
       "      <td>Towards the effectiveness of Deep Convolutiona...</td>\n",
       "      <td>Deep Learning is considered to be a quite youn...</td>\n",
       "      <td>Towards the effectiveness of Deep Convolutiona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>human</td>\n",
       "      <td>Helen</td>\n",
       "      <td>Helen tells the story of a young orphan, Hele...</td>\n",
       "      <td>Helen Helen tells the story of a young orphan,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model                                              title  \\\n",
       "0  human  My mom is shaming me for wanting to get off of...   \n",
       "1   gpt4  DAE feel like their dreams make up memories? A...   \n",
       "2   gpt4                    FBI agent colludes with analyst   \n",
       "3  human  Towards the effectiveness of Deep Convolutiona...   \n",
       "4  human                                              Helen   \n",
       "\n",
       "                                          generation  \\\n",
       "0  I have been medicated for ADHD and anxiety for...   \n",
       "1  I've been experiencing this strange phenomenon...   \n",
       "2  An FBI agent stands accused of colluding with ...   \n",
       "3  Deep Learning is considered to be a quite youn...   \n",
       "4   Helen tells the story of a young orphan, Hele...   \n",
       "\n",
       "                                                text  \n",
       "0  My mom is shaming me for wanting to get off of...  \n",
       "1  DAE feel like their dreams make up memories? A...  \n",
       "2  FBI agent colludes with analystAn FBI agent st...  \n",
       "3  Towards the effectiveness of Deep Convolutiona...  \n",
       "4  Helen Helen tells the story of a young orphan,...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:37:37.351664Z",
     "iopub.status.busy": "2025-06-12T00:37:37.351381Z",
     "iopub.status.idle": "2025-06-12T00:37:37.355507Z",
     "shell.execute_reply": "2025-06-12T00:37:37.354721Z",
     "shell.execute_reply.started": "2025-06-12T00:37:37.351645Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "label_map={\n",
    "    'human':0,\n",
    "    'gpt4':1,\n",
    "    'chatgpt':1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:38:11.746542Z",
     "iopub.status.busy": "2025-06-12T00:38:11.745849Z",
     "iopub.status.idle": "2025-06-12T00:38:11.757709Z",
     "shell.execute_reply": "2025-06-12T00:38:11.756915Z",
     "shell.execute_reply.started": "2025-06-12T00:38:11.746512Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35/946050259.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_main['model']=df_main['model'].map(label_map);\n"
     ]
    }
   ],
   "source": [
    "df_main['model']=df_main['model'].map(label_map);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:45:39.966263Z",
     "iopub.status.busy": "2025-06-12T00:45:39.965543Z",
     "iopub.status.idle": "2025-06-12T00:45:39.975465Z",
     "shell.execute_reply": "2025-06-12T00:45:39.974569Z",
     "shell.execute_reply.started": "2025-06-12T00:45:39.966242Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df=df_main[[\"model\",\"text\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stage 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:45:54.107309Z",
     "iopub.status.busy": "2025-06-12T00:45:54.106798Z",
     "iopub.status.idle": "2025-06-12T00:45:54.111633Z",
     "shell.execute_reply": "2025-06-12T00:45:54.111050Z",
     "shell.execute_reply.started": "2025-06-12T00:45:54.107283Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# If you haven’t already:w\n",
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer    = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:45:59.640837Z",
     "iopub.status.busy": "2025-06-12T00:45:59.640576Z",
     "iopub.status.idle": "2025-06-12T00:45:59.646064Z",
     "shell.execute_reply": "2025-06-12T00:45:59.645314Z",
     "shell.execute_reply.started": "2025-06-12T00:45:59.640817Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # 1. Replace URLs, hashtags, mentions, numbers, currency\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', 'HTTPADDR', text)\n",
    "    text = re.sub(r'#\\w+', 'HSTIDS', text)\n",
    "    text = re.sub(r'@\\w+', 'USERID', text)\n",
    "    text = re.sub(r'\\d+', 'NUMIDS', text)\n",
    "    text = re.sub(r'[€£\\$]', 'CURRIDS', text)\n",
    "    # 2. Drop non-ASCII (emojis, non-alphabetic punctuation)\n",
    "    text = text.encode('ascii', errors='ignore').decode()\n",
    "    # 3. Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # 4. Tokenize & lowercase\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    # 5. Remove stop-words & stem\n",
    "    tokens = [stemmer.stem(tok) for tok in tokens if tok not in stop_words]\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:46:06.075404Z",
     "iopub.status.busy": "2025-06-12T00:46:06.075127Z",
     "iopub.status.idle": "2025-06-12T00:49:05.424746Z",
     "shell.execute_reply": "2025-06-12T00:49:05.423969Z",
     "shell.execute_reply.started": "2025-06-12T00:46:06.075382Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  My mom is shaming me for wanting to get off of...   \n",
      "1  DAE feel like their dreams make up memories? A...   \n",
      "2  FBI agent colludes with analystAn FBI agent st...   \n",
      "\n",
      "                                              tokens  \n",
      "0  [mom, shame, want, get, medic, instead, go, wa...  \n",
      "1  [dae, feel, like, dream, make, memori, cant, t...  \n",
      "2  [fbi, agent, collud, analystan, fbi, agent, st...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35/2073079088.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tokens'] = df['text'].map(preprocess_text)\n"
     ]
    }
   ],
   "source": [
    "# Assume df is already loaded, with columns 'text' and 'model'\n",
    "df['tokens'] = df['text'].map(preprocess_text)\n",
    "# Quick sanity-check\n",
    "print(df[['text','tokens']].head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:49:05.426177Z",
     "iopub.status.busy": "2025-06-12T00:49:05.425904Z",
     "iopub.status.idle": "2025-06-12T00:49:07.201558Z",
     "shell.execute_reply": "2025-06-12T00:49:07.200776Z",
     "shell.execute_reply.started": "2025-06-12T00:49:05.426158Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common: [('numid', 206108), ('th', 91620), ('n', 54717), ('nd', 53078), ('f', 45438), ('numidsnumid', 45328), ('also', 30650), ('cup', 30536), ('one', 29143), ('time', 26349)]\n",
      "A few words with freq=1: ['mmnttng', 'furycaptain', 'heartgrip', 'duallevel', 'zkr', 'sglk', 'rhthmst', 'ndss', 'flatsnumid', 'setswhil']\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Flatten all token lists into one big list\n",
    "all_tokens = [tok for tokens in df['tokens'] for tok in tokens]\n",
    "freq_map   = Counter(all_tokens)\n",
    "\n",
    "# Inspect the 10 most common & 10 rarest words\n",
    "print(\"Most common:\", freq_map.most_common(10))\n",
    "rare = [w for w, c in freq_map.items() if c == 1]\n",
    "print(\"A few words with freq=1:\", rare[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:49:19.051671Z",
     "iopub.status.busy": "2025-06-12T00:49:19.051413Z",
     "iopub.status.idle": "2025-06-12T00:49:21.222987Z",
     "shell.execute_reply": "2025-06-12T00:49:21.222240Z",
     "shell.execute_reply.started": "2025-06-12T00:49:19.051653Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              tokens\n",
      "0  [mom, shame, want, get, medic, instead, go, wa...\n",
      "1  [dae, feel, like, dream, make, memori, cant, t...\n",
      "2  [fbi, agent, collud, rareWord, fbi, agent, sta...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35/2439514293.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tokens'] = df['tokens'].map(replace_rare)\n"
     ]
    }
   ],
   "source": [
    "RARE_THRESHOLD = 10\n",
    "def replace_rare(tokens):\n",
    "    return [tok if freq_map[tok] >= RARE_THRESHOLD else 'rareWord'\n",
    "            for tok in tokens]\n",
    "\n",
    "df['tokens'] = df['tokens'].map(replace_rare)\n",
    "# Check again\n",
    "print(df[['tokens']].head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:51:43.363501Z",
     "iopub.status.busy": "2025-06-12T00:51:43.362799Z",
     "iopub.status.idle": "2025-06-12T00:51:49.861336Z",
     "shell.execute_reply": "2025-06-12T00:51:49.860513Z",
     "shell.execute_reply.started": "2025-06-12T00:51:43.363476Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"stage1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stage 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:54:30.638668Z",
     "iopub.status.busy": "2025-06-12T00:54:30.638004Z",
     "iopub.status.idle": "2025-06-12T00:54:30.674583Z",
     "shell.execute_reply": "2025-06-12T00:54:30.674007Z",
     "shell.execute_reply.started": "2025-06-12T00:54:30.638639Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset shape: (10000, 3)\n",
      "model\n",
      "1    5000\n",
      "0    5000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df has columns 'tokens' and 'model' (0=human, 1=AI)\n",
    "n = 5000\n",
    "\n",
    "# 1. Sample 5 000 from each class\n",
    "df0 = df[df['model'] == 0].sample(n=min(n, len(df[df['model']==0])), random_state=42)\n",
    "df1 = df[df['model'] == 1].sample(n=min(n, len(df[df['model']==1])), random_state=42)\n",
    "\n",
    "# 2. Combine & shuffle\n",
    "df_sub = pd.concat([df0, df1]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(\"Subset shape:\", df_sub.shape)\n",
    "print(df_sub['model'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T00:56:02.569341Z",
     "iopub.status.busy": "2025-06-12T00:56:02.568776Z",
     "iopub.status.idle": "2025-06-12T00:56:03.761840Z",
     "shell.execute_reply": "2025-06-12T00:56:03.761098Z",
     "shell.execute_reply.started": "2025-06-12T00:56:02.569317Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_features=50000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=50000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(max_features=50000)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# We need a string corpus—join each token list into space-separated text\n",
    "corpus = [\" \".join(tokens) for tokens in df_sub['tokens']]\n",
    "\n",
    "# Fit TF–IDF on the full corpus (IDF only)\n",
    "# 4. Fit a new TF–IDF on just the subset\n",
    "tfidf_vec_sub = TfidfVectorizer(max_features=50000)\n",
    "tfidf_vec_sub.fit(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T01:01:31.865290Z",
     "iopub.status.busy": "2025-06-12T01:01:31.864164Z",
     "iopub.status.idle": "2025-06-12T01:01:31.873366Z",
     "shell.execute_reply": "2025-06-12T01:01:31.872664Z",
     "shell.execute_reply.started": "2025-06-12T01:01:31.865235Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Parameters\n",
    "MAX_VOCAB_SIZE = 48   # number of tokens per tweet to keep\n",
    "EPS = 1e-8            # small constant for division\n",
    "\n",
    "def build_cooccurrence_matrix(tokens, tfidf_vec):\n",
    "    \"\"\"\n",
    "    tokens: list of preprocessed tokens for one tweet\n",
    "    tfidf_vec: fitted TfidfVectorizer\n",
    "    Returns: M×M numpy array, where M = MAX_VOCAB_SIZE\n",
    "    \"\"\"\n",
    "    # 1. Select up to M unique tokens, preserving order\n",
    "    uniq = []\n",
    "    for t in tokens:\n",
    "        if t not in uniq:\n",
    "            uniq.append(t)\n",
    "        if len(uniq) >= MAX_VOCAB_SIZE:\n",
    "            break\n",
    "    # Pad with a special token if needed\n",
    "    while len(uniq) < MAX_VOCAB_SIZE:\n",
    "        uniq.append('<PAD>')\n",
    "\n",
    "    # 2. Compute TF–IDF vector for this tweet over our vocab\n",
    "    text = \" \".join(tokens)\n",
    "    tfidf_row = tfidf_vec.transform([text]).toarray()[0]  # shape (V_full,)\n",
    "    # Extract the TF–IDF values for our uniq tokens\n",
    "    idf_vals = np.array([ tfidf_row[ tfidf_vec.vocabulary_.get(w, -1) ] \n",
    "                          if w in tfidf_vec.vocabulary_ else 0.0\n",
    "                          for w in uniq ])\n",
    "\n",
    "    # 3. Count frequencies in the tweet\n",
    "    freq = {w: tokens.count(w) for w in uniq}\n",
    "\n",
    "    # 4. Build M×M matrix\n",
    "    M = MAX_VOCAB_SIZE\n",
    "    mat = np.zeros((M, M), dtype=float)\n",
    "    # Diagonal ← TF–IDF\n",
    "    for i in range(M):\n",
    "        mat[i, i] = idf_vals[i]\n",
    "\n",
    "    # Off-diagonals\n",
    "    for i in range(M):\n",
    "        for j in range(M):\n",
    "            if i == j:\n",
    "                continue\n",
    "            # co-occurrence count\n",
    "            cooc = 1 if (freq.get(uniq[i], 0) > 0 and freq.get(uniq[j],0) > 0) else 0\n",
    "            if i > j:\n",
    "                mat[i, j] = cooc\n",
    "            else:  # i < j, normalized “correlation”\n",
    "                denom = freq.get(uniq[i],0) * freq.get(uniq[j],0) + EPS\n",
    "                mat[i, j] = cooc / denom\n",
    "\n",
    "    return mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T01:01:33.000450Z",
     "iopub.status.busy": "2025-06-12T01:01:33.000167Z",
     "iopub.status.idle": "2025-06-12T01:01:33.010519Z",
     "shell.execute_reply": "2025-06-12T01:01:33.009798Z",
     "shell.execute_reply.started": "2025-06-12T01:01:33.000431Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (48, 48)\n",
      "[[0.27441466 0.33333333 0.16666667 ... 0.16666667 0.33333333 0.33333333]\n",
      " [1.         0.0923223  0.5        ... 0.5        0.99999999 0.99999999]\n",
      " [1.         1.         0.09663782 ... 0.25       0.5        0.5       ]\n",
      " ...\n",
      " [1.         1.         1.         ... 0.10805361 0.5        0.5       ]\n",
      " [1.         1.         1.         ... 1.         0.05201217 0.99999999]\n",
      " [1.         1.         1.         ... 1.         1.         0.07235461]]\n"
     ]
    }
   ],
   "source": [
    "# Example: build and store the matrix for the first tweet\n",
    "example_mat = build_cooccurrence_matrix(df.loc[0, 'tokens'], tfidf_vec)\n",
    "print(\"Shape:\", example_mat.shape)\n",
    "print(example_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T01:01:36.087449Z",
     "iopub.status.busy": "2025-06-12T01:01:36.087173Z",
     "iopub.status.idle": "2025-06-12T01:01:58.338458Z",
     "shell.execute_reply": "2025-06-12T01:01:58.337856Z",
     "shell.execute_reply.started": "2025-06-12T01:01:36.087429Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/10000] matrices built\n",
      "[1000/10000] matrices built\n",
      "[2000/10000] matrices built\n",
      "[3000/10000] matrices built\n",
      "[4000/10000] matrices built\n",
      "[5000/10000] matrices built\n",
      "[6000/10000] matrices built\n",
      "[7000/10000] matrices built\n",
      "[8000/10000] matrices built\n",
      "[9000/10000] matrices built\n"
     ]
    }
   ],
   "source": [
    "# Pre-allocate and build\n",
    "N_sub = len(df_sub)\n",
    "M = MAX_VOCAB_SIZE\n",
    "matrices_sub = np.zeros((N_sub, M, M), dtype=float)\n",
    "\n",
    "for idx, tokens in enumerate(df_sub['tokens']):\n",
    "    matrices_sub[idx] = build_cooccurrence_matrix(tokens, tfidf_vec_sub)\n",
    "    if idx % 1000 == 0:\n",
    "        print(f\"[{idx}/{N_sub}] matrices built\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T01:02:10.730625Z",
     "iopub.status.busy": "2025-06-12T01:02:10.730353Z",
     "iopub.status.idle": "2025-06-12T01:02:10.787221Z",
     "shell.execute_reply": "2025-06-12T01:02:10.786596Z",
     "shell.execute_reply.started": "2025-06-12T01:02:10.730604Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MatrixDataset(Dataset):\n",
    "    def __init__(self, matrices):\n",
    "        # matrices: np.array of shape (N, M, M)\n",
    "        self.mats = torch.from_numpy(matrices).float().unsqueeze(1)  # → (N,1,M,M)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.mats.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.mats[idx]\n",
    "\n",
    "# Replace `matrices_sub` with your array; choose batch_size=4 as in paper\n",
    "dataset = MatrixDataset(matrices_sub)\n",
    "loader  = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=2, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T01:02:11.235363Z",
     "iopub.status.busy": "2025-06-12T01:02:11.235118Z",
     "iopub.status.idle": "2025-06-12T01:02:11.247681Z",
     "shell.execute_reply": "2025-06-12T01:02:11.247110Z",
     "shell.execute_reply.started": "2025-06-12T01:02:11.235346Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class UNetGenerator(nn.Module):\n",
    "    def __init__(self, in_ch=1, ngf=64):\n",
    "        super().__init__()\n",
    "        # Encoder (downsamples by 2 each layer)\n",
    "        self.enc1 = nn.Sequential(nn.Conv2d(in_ch,    ngf, 4, 2, 1),\n",
    "                                   nn.BatchNorm2d(ngf), nn.LeakyReLU(0.2))\n",
    "        self.enc2 = nn.Sequential(nn.Conv2d(ngf,  ngf*2, 4, 2, 1),\n",
    "                                   nn.BatchNorm2d(ngf*2), nn.LeakyReLU(0.2))\n",
    "        self.enc3 = nn.Sequential(nn.Conv2d(ngf*2,ngf*4, 4, 2, 1),\n",
    "                                   nn.BatchNorm2d(ngf*4), nn.LeakyReLU(0.2))\n",
    "        self.enc4 = nn.Sequential(nn.Conv2d(ngf*4,ngf*8, 4, 2, 1),\n",
    "                                   nn.BatchNorm2d(ngf*8), nn.LeakyReLU(0.2))\n",
    "        # Decoder (upsamples by 2 each layer, with skip-connections)\n",
    "        self.dec1 = nn.Sequential(nn.ConvTranspose2d(ngf*8,   ngf*4, 4, 2, 1),\n",
    "                                   nn.BatchNorm2d(ngf*4), nn.ReLU())\n",
    "        self.dec2 = nn.Sequential(nn.ConvTranspose2d(ngf*8,   ngf*2, 4, 2, 1),\n",
    "                                   nn.BatchNorm2d(ngf*2), nn.ReLU())\n",
    "        self.dec3 = nn.Sequential(nn.ConvTranspose2d(ngf*4,     ngf, 4, 2, 1),\n",
    "                                   nn.BatchNorm2d(ngf),   nn.ReLU())\n",
    "        self.dec4 = nn.Sequential(nn.ConvTranspose2d(ngf*2, in_ch, 4, 2, 1),\n",
    "                                   nn.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)              # → [B, ngf,    M/2,   M/2]\n",
    "        e2 = self.enc2(e1)             # → [B,2ngf,   M/4,   M/4]\n",
    "        e3 = self.enc3(e2)             # → [B,4ngf,   M/8,   M/8]\n",
    "        e4 = self.enc4(e3)             # → [B,8ngf,   M/16,  M/16]\n",
    "        d1 = self.dec1(e4)             \n",
    "        d2 = self.dec2(torch.cat([d1, e3], dim=1))\n",
    "        d3 = self.dec3(torch.cat([d2, e2], dim=1))\n",
    "        d4 = self.dec4(torch.cat([d3, e1], dim=1))\n",
    "        return d4, d3  # d4: reconstructed matrix; d3: feature map\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_ch=1, ndf=64):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_ch,   ndf,   4, 2, 1), nn.BatchNorm2d(ndf),   nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(ndf,    ndf*2,  4, 2, 1), nn.BatchNorm2d(ndf*2), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(ndf*2,  ndf*4,  4, 2, 1), nn.BatchNorm2d(ndf*4), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(ndf*4,     1,   4, 1, 0)                      # → [B,1,1,1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x).view(-1)  # flatten to [B]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T01:02:11.788099Z",
     "iopub.status.busy": "2025-06-12T01:02:11.787792Z",
     "iopub.status.idle": "2025-06-12T01:02:11.792967Z",
     "shell.execute_reply": "2025-06-12T01:02:11.792407Z",
     "shell.execute_reply.started": "2025-06-12T01:02:11.788078Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.autograd as autograd\n",
    "\n",
    "def gradient_penalty(D, real, fake, device):\n",
    "    B = real.size(0)\n",
    "    alpha = torch.rand(B, 1, 1, 1, device=device)\n",
    "    interp = (alpha * real + (1-alpha) * fake).requires_grad_(True)\n",
    "    d_interp = D(interp)\n",
    "    grads = autograd.grad(outputs=d_interp, inputs=interp,\n",
    "                          grad_outputs=torch.ones_like(d_interp),\n",
    "                          create_graph=True, retain_graph=True)[0]\n",
    "    grads = grads.view(B, -1)\n",
    "    return ((grads.norm(2, dim=1) - 1)**2).mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T01:02:12.447204Z",
     "iopub.status.busy": "2025-06-12T01:02:12.446601Z",
     "iopub.status.idle": "2025-06-12T01:36:58.294728Z",
     "shell.execute_reply": "2025-06-12T01:36:58.293686Z",
     "shell.execute_reply.started": "2025-06-12T01:02:12.447181Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/30]  lossD: -1.3588  lossG: 3.5561\n",
      "[Epoch 2/30]  lossD: -1.5622  lossG: 2.0235\n",
      "[Epoch 3/30]  lossD: -2.5503  lossG: 1.3811\n",
      "[Epoch 4/30]  lossD: -0.2104  lossG: 1.7168\n",
      "[Epoch 5/30]  lossD: -0.3239  lossG: 1.3917\n",
      "[Epoch 6/30]  lossD: 0.0055  lossG: 0.5474\n",
      "[Epoch 7/30]  lossD: -0.0016  lossG: 0.3533\n",
      "[Epoch 8/30]  lossD: 0.0169  lossG: 0.0732\n",
      "[Epoch 9/30]  lossD: -0.0018  lossG: 0.2214\n",
      "[Epoch 10/30]  lossD: -0.0068  lossG: 0.1156\n",
      "[Epoch 11/30]  lossD: -0.0115  lossG: 0.8125\n",
      "[Epoch 12/30]  lossD: -0.0055  lossG: 0.3588\n",
      "[Epoch 13/30]  lossD: 0.0010  lossG: 0.4361\n",
      "[Epoch 14/30]  lossD: -0.0024  lossG: 0.7324\n",
      "[Epoch 15/30]  lossD: -0.0044  lossG: 0.8194\n",
      "[Epoch 16/30]  lossD: -0.0017  lossG: 1.0061\n",
      "[Epoch 17/30]  lossD: -0.0027  lossG: 1.4455\n",
      "[Epoch 18/30]  lossD: -0.0110  lossG: 1.3118\n",
      "[Epoch 19/30]  lossD: -0.0043  lossG: 1.3177\n",
      "[Epoch 20/30]  lossD: -0.0032  lossG: 1.2204\n",
      "[Epoch 21/30]  lossD: -0.0031  lossG: 1.5761\n",
      "[Epoch 22/30]  lossD: -0.0028  lossG: 1.7660\n",
      "[Epoch 23/30]  lossD: -0.0076  lossG: 1.8535\n",
      "[Epoch 24/30]  lossD: -0.0063  lossG: 1.8167\n",
      "[Epoch 25/30]  lossD: -0.0039  lossG: 2.0525\n",
      "[Epoch 26/30]  lossD: 0.0027  lossG: 2.0133\n",
      "[Epoch 27/30]  lossD: -0.0037  lossG: 2.3384\n",
      "[Epoch 28/30]  lossD: -0.0053  lossG: 2.0505\n",
      "[Epoch 29/30]  lossD: -0.0028  lossG: 2.2983\n",
      "[Epoch 30/30]  lossD: -0.0042  lossG: 2.3362\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "G = UNetGenerator().to(device)\n",
    "D = Discriminator().to(device)\n",
    "\n",
    "optG = optim.Adam(G.parameters(), lr=1e-4, betas=(0.5, 0.9))\n",
    "optD = optim.Adam(D.parameters(), lr=1e-4, betas=(0.5, 0.9))\n",
    "\n",
    "lambda_gp = 10    # WGAN-GP gradient penalty weight\n",
    "lambda_l1 = 100   # L1 reconstruction loss weight\n",
    "n_epochs  = 30    # start smaller; increase if needed\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    for real in loader:\n",
    "        real = real.to(device)\n",
    "\n",
    "        # ——— Discriminator step ———\n",
    "        fake, _ = G(real + 0.01*torch.randn_like(real))  # small input noise\n",
    "        d_real = D(real)\n",
    "        d_fake = D(fake.detach())\n",
    "        gp     = gradient_penalty(D, real, fake.detach(), device)\n",
    "        lossD  = -(d_real.mean() - d_fake.mean()) + lambda_gp * gp\n",
    "\n",
    "        optD.zero_grad()\n",
    "        lossD.backward()\n",
    "        optD.step()\n",
    "\n",
    "        # ——— Generator step ———\n",
    "        fake, _   = G(real)\n",
    "        lossG_adv = -D(fake).mean()\n",
    "        lossG_l1  = F.l1_loss(fake, real) * lambda_l1\n",
    "        lossG     = lossG_adv + lossG_l1\n",
    "\n",
    "        optG.zero_grad()\n",
    "        lossG.backward()\n",
    "        optG.step()\n",
    "\n",
    "    print(f\"[Epoch {epoch}/{n_epochs}]  lossD: {lossD.item():.4f}  lossG: {lossG.item():.4f}\")\n",
    "\n",
    "    # Optional: save checkpoints every few epochs\n",
    "    if epoch % 10 == 0:\n",
    "        torch.save(G.state_dict(), f'G_epoch{epoch}.pth')\n",
    "        torch.save(D.state_dict(), f'D_epoch{epoch}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T01:37:21.670494Z",
     "iopub.status.busy": "2025-06-12T01:37:21.669919Z",
     "iopub.status.idle": "2025-06-12T01:37:21.710419Z",
     "shell.execute_reply": "2025-06-12T01:37:21.709851Z",
     "shell.execute_reply.started": "2025-06-12T01:37:21.670463Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNetGenerator(\n",
       "  (enc1): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (enc2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (enc3): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (enc4): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (dec1): Sequential(\n",
       "    (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (dec2): Sequential(\n",
       "    (0): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (dec3): Sequential(\n",
       "    (0): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (dec4): Sequential(\n",
       "    (0): ConvTranspose2d(128, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you saved checkpoints, load the final or best one:\n",
    "G.load_state_dict(torch.load('G_epoch30.pth', map_location=device))\n",
    "G.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T01:39:06.181519Z",
     "iopub.status.busy": "2025-06-12T01:39:06.180618Z",
     "iopub.status.idle": "2025-06-12T01:39:06.664192Z",
     "shell.execute_reply": "2025-06-12T01:39:06.663352Z",
     "shell.execute_reply.started": "2025-06-12T01:39:06.181478Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected feature dimension: 36864\n"
     ]
    }
   ],
   "source": [
    "# Grab a single batch\n",
    "mats, idxs = next(iter(idx_loader))\n",
    "mats = mats.to(device)\n",
    "with torch.no_grad():\n",
    "    _, d3 = G(mats)\n",
    "B, C, H, W = d3.shape\n",
    "feat_dim = C * H * W\n",
    "print(\"Detected feature dimension:\", feat_dim)  # e.g. 16384\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stage 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T01:40:19.628427Z",
     "iopub.status.busy": "2025-06-12T01:40:19.628087Z",
     "iopub.status.idle": "2025-06-12T01:40:28.396309Z",
     "shell.execute_reply": "2025-06-12T01:40:28.395101Z",
     "shell.execute_reply.started": "2025-06-12T01:40:19.628392Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred feature dimension: C=64, H=24, W=24 → feat_dim=36864\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "495ffa540b124e029913e88a91853159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting GAN features:   0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 4.1. Prepare an indexed dataset for matrices_sub\n",
    "class IndexedMatrixDataset(Dataset):\n",
    "    def __init__(self, matrices):\n",
    "        # matrices: NumPy array of shape (N, M, M)\n",
    "        self.mats = torch.from_numpy(matrices).float().unsqueeze(1)  # → (N,1,M,M)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.mats.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.mats[idx], idx\n",
    "\n",
    "# Create loader (no shuffle so idxs line up)\n",
    "idx_ds = IndexedMatrixDataset(matrices_sub)\n",
    "idx_loader = DataLoader(idx_ds, batch_size=16, shuffle=False, num_workers=2)\n",
    "\n",
    "# 4.2. Ensure your Generator is in eval mode and on the correct device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "G.eval()\n",
    "G.to(device)\n",
    "\n",
    "# 4.3. Infer feat_dim from one batch\n",
    "with torch.no_grad():\n",
    "    sample_mats, sample_idxs = next(iter(idx_loader))\n",
    "    sample_mats = sample_mats.to(device)\n",
    "    _, sample_d3 = G(sample_mats)        # sample_d3 shape: [B, C, H, W]\n",
    "    B, C, H, W = sample_d3.shape\n",
    "    feat_dim = C * H * W\n",
    "    print(f\"Inferred feature dimension: C={C}, H={H}, W={W} → feat_dim={feat_dim}\")\n",
    "\n",
    "# 4.4. Allocate the features array\n",
    "N = len(idx_ds)\n",
    "features = np.zeros((N, feat_dim), dtype=np.float32)\n",
    "\n",
    "# 4.5. Extract and store features\n",
    "with torch.no_grad():\n",
    "    for mats, idxs in tqdm(idx_loader, desc=\"Extracting GAN features\"):\n",
    "        mats = mats.to(device)\n",
    "        _, d3 = G(mats)                     # d3: [B, C, H, W]\n",
    "        flat = d3.view(d3.size(0), -1).cpu().numpy()  # → [B, feat_dim]\n",
    "        for i, orig_idx in enumerate(idxs):\n",
    "            features[orig_idx] = flat[i]\n",
    "\n",
    "# Now `features` is an (N, feat_dim) array of your GAN-based representations\n",
    "# You can proceed to Stage 5: Random Forest training with `features` and your labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stage 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T01:41:01.906225Z",
     "iopub.status.busy": "2025-06-12T01:41:01.905713Z",
     "iopub.status.idle": "2025-06-12T01:41:02.983733Z",
     "shell.execute_reply": "2025-06-12T01:41:02.982983Z",
     "shell.execute_reply.started": "2025-06-12T01:41:01.906186Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (8000, 36864) (8000,)\n",
      "Validation set: (2000, 36864) (2000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# `features` is shape (N, feat_dim); `df_sub['model']` holds 0/1 labels\n",
    "X = features\n",
    "y = df_sub['model'].values\n",
    "\n",
    "# 80/20 stratified split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training set:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set:\", X_val.shape, y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T01:41:12.282508Z",
     "iopub.status.busy": "2025-06-12T01:41:12.282227Z",
     "iopub.status.idle": "2025-06-12T01:42:40.259003Z",
     "shell.execute_reply": "2025-06-12T01:42:40.258344Z",
     "shell.execute_reply.started": "2025-06-12T01:41:12.282487Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed tree weights. Sample: [0.00998749 0.01008257 0.01004246 0.00995778 0.01004543]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# 1) Train a standard Random Forest\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,      # number of trees\n",
    "    oob_score=True,        # enable out-of-bag scoring\n",
    "    n_jobs=-1,             # use all cores\n",
    "    random_state=42\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# 2) Compute each tree’s accuracy on the training set (or OOB samples)\n",
    "tree_weights = []\n",
    "for tree in rf.estimators_:\n",
    "    preds = tree.predict(X_train)\n",
    "    acc   = accuracy_score(y_train, preds)\n",
    "    tree_weights.append(acc)\n",
    "\n",
    "tree_weights = np.array(tree_weights)\n",
    "tree_weights = tree_weights / tree_weights.sum()   # normalize to sum = 1\n",
    "\n",
    "print(\"Computed tree weights. Sample:\", tree_weights[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T01:42:51.063803Z",
     "iopub.status.busy": "2025-06-12T01:42:51.062888Z",
     "iopub.status.idle": "2025-06-12T01:42:51.068170Z",
     "shell.execute_reply": "2025-06-12T01:42:51.067523Z",
     "shell.execute_reply.started": "2025-06-12T01:42:51.063769Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def weighted_rf_predict(rf, tree_weights, X):\n",
    "    \"\"\"\n",
    "    rf           : trained RandomForestClassifier\n",
    "    tree_weights: array of shape (n_estimators,) summing to 1\n",
    "    X            : feature array (n_samples, feat_dim)\n",
    "\n",
    "    Returns:\n",
    "      y_pred (n_samples,) binary predictions,\n",
    "      y_prob (n_samples,) weighted probability of class 1\n",
    "    \"\"\"\n",
    "    # Initialize probability accumulator\n",
    "    probs = np.zeros(X.shape[0], dtype=float)\n",
    "\n",
    "    # Accumulate each tree’s predicted probability for class 1, weighted\n",
    "    for w, tree in zip(tree_weights, rf.estimators_):\n",
    "        probs += w * tree.predict_proba(X)[:, 1]\n",
    "\n",
    "    # Binary decision at 0.5 threshold\n",
    "    y_pred = (probs >= 0.5).astype(int)\n",
    "    return y_pred, probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T01:43:22.611175Z",
     "iopub.status.busy": "2025-06-12T01:43:22.610594Z",
     "iopub.status.idle": "2025-06-12T01:43:26.075622Z",
     "shell.execute_reply": "2025-06-12T01:43:26.075000Z",
     "shell.execute_reply.started": "2025-06-12T01:43:22.611149Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6813    0.6990    0.6900      1000\n",
      "           1     0.6910    0.6730    0.6819      1000\n",
      "\n",
      "    accuracy                         0.6860      2000\n",
      "   macro avg     0.6861    0.6860    0.6859      2000\n",
      "weighted avg     0.6861    0.6860    0.6859      2000\n",
      "\n",
      "Validation AUC: 0.7650\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Get predictions\n",
    "y_pred, y_prob = weighted_rf_predict(rf, tree_weights, X_val)\n",
    "\n",
    "# Classification metrics\n",
    "print(classification_report(y_val, y_pred, digits=4))\n",
    "\n",
    "# AUC\n",
    "auc = roc_auc_score(y_val, y_prob)\n",
    "print(f\"Validation AUC: {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T01:43:45.039452Z",
     "iopub.status.busy": "2025-06-12T01:43:45.038726Z",
     "iopub.status.idle": "2025-06-12T01:54:36.283139Z",
     "shell.execute_reply": "2025-06-12T01:54:36.282412Z",
     "shell.execute_reply.started": "2025-06-12T01:43:45.039427Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.6709 ± 0.0115\n",
      "PREC: 0.6747 ± 0.0125\n",
      "REC: 0.6602 ± 0.0128\n",
      "F1: 0.6673 ± 0.0116\n",
      "AUC: 0.7471 ± 0.0137\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "metrics = {'acc': [], 'prec': [], 'rec': [], 'f1': [], 'auc': []}\n",
    "\n",
    "for train_idx, val_idx in skf.split(X, y):\n",
    "    X_tr, X_va = X[train_idx], X[val_idx]\n",
    "    y_tr, y_va = y[train_idx], y[val_idx]\n",
    "\n",
    "    # Train RF\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    rf.fit(X_tr, y_tr)\n",
    "\n",
    "    # Compute tree weights on training set\n",
    "    tw = []\n",
    "    for tree in rf.estimators_:\n",
    "        pred_tr = tree.predict(X_tr)\n",
    "        tw.append(accuracy_score(y_tr, pred_tr))\n",
    "    tw = np.array(tw)\n",
    "    tw = tw / tw.sum()\n",
    "\n",
    "    # Predict on validation fold\n",
    "    y_va_pred, y_va_prob = weighted_rf_predict(rf, tw, X_va)\n",
    "\n",
    "    # Record metrics\n",
    "    metrics['acc'].append(accuracy_score(y_va, y_va_pred))\n",
    "    metrics['prec'].append(precision_score(y_va, y_va_pred))\n",
    "    metrics['rec'].append(recall_score(y_va, y_va_pred))\n",
    "    metrics['f1'].append(f1_score(y_va, y_va_pred))\n",
    "    metrics['auc'].append(roc_auc_score(y_va, y_va_prob))\n",
    "\n",
    "# Print average and std\n",
    "for m in metrics:\n",
    "    vals = metrics[m]\n",
    "    print(f\"{m.upper()}: {np.mean(vals):.4f} ± {np.std(vals):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T01:54:36.284385Z",
     "iopub.status.busy": "2025-06-12T01:54:36.284157Z",
     "iopub.status.idle": "2025-06-12T01:54:40.132356Z",
     "shell.execute_reply": "2025-06-12T01:54:40.131608Z",
     "shell.execute_reply.started": "2025-06-12T01:54:36.284368Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9670\n",
      "Precision: 0.9670\n",
      "Recall   : 0.9670\n",
      "F1-score : 0.9670\n",
      "AUC      : 0.9978\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9670    0.9670    0.9670      1000\n",
      "           1     0.9670    0.9670    0.9670      1000\n",
      "\n",
      "    accuracy                         0.9670      2000\n",
      "   macro avg     0.9670    0.9670    0.9670      2000\n",
      "weighted avg     0.9670    0.9670    0.9670      2000\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1) Get your predictions & probabilities\n",
    "y_pred, y_prob = weighted_rf_predict(rf, tree_weights, X_val)\n",
    "\n",
    "# 2) Compute metrics\n",
    "acc   = accuracy_score(y_val, y_pred)\n",
    "prec  = precision_score(y_val, y_pred)\n",
    "rec   = recall_score(y_val, y_pred)\n",
    "f1    = f1_score(y_val, y_pred)\n",
    "auc   = roc_auc_score(y_val, y_prob)\n",
    "\n",
    "print(f\"Accuracy : {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall   : {rec:.4f}\")\n",
    "print(f\"F1-score : {f1:.4f}\")\n",
    "print(f\"AUC      : {auc:.4f}\\n\")\n",
    "\n",
    "# 3) Full classification report (includes support)\n",
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(y_val, y_pred, digits=4))\n",
    "\n",
    "# 4) Confusion matrix\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "plt.figure(figsize=(4,3))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "            xticklabels=[0,1], yticklabels=[0,1])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T01:56:48.213989Z",
     "iopub.status.busy": "2025-06-12T01:56:48.213406Z",
     "iopub.status.idle": "2025-06-12T01:56:51.819246Z",
     "shell.execute_reply": "2025-06-12T01:56:51.818580Z",
     "shell.execute_reply.started": "2025-06-12T01:56:48.213941Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RF →  Acc: 0.9660, AUC: 0.9978\n",
      "Weighted RF →  Acc: 0.9670, AUC: 0.9978\n"
     ]
    }
   ],
   "source": [
    "# Baseline (unweighted) RF\n",
    "y_pred_base = rf.predict(X_val)\n",
    "acc_base  = accuracy_score(y_val, y_pred_base)\n",
    "auc_base  = roc_auc_score(y_val, rf.predict_proba(X_val)[:,1])\n",
    "print(f\"Baseline RF →  Acc: {acc_base:.4f}, AUC: {auc_base:.4f}\")\n",
    "\n",
    "# Weighted RF\n",
    "y_pred_w, y_prob_w = weighted_rf_predict(rf, tree_weights, X_val)\n",
    "acc_w  = accuracy_score(y_val, y_pred_w)\n",
    "auc_w  = roc_auc_score(y_val, y_prob_w)\n",
    "print(f\"Weighted RF →  Acc: {acc_w:.4f}, AUC: {auc_w:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6772480,
     "sourceId": 10897694,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
