{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10897694,"sourceType":"datasetVersion","datasetId":6772480}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-12T00:20:19.213829Z","iopub.execute_input":"2025-06-12T00:20:19.214060Z","iopub.status.idle":"2025-06-12T00:20:20.968057Z","shell.execute_reply.started":"2025-06-12T00:20:19.214042Z","shell.execute_reply":"2025-06-12T00:20:20.967305Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/raid-dataset/extra.csv\n/kaggle/input/raid-dataset/train.csv\n/kaggle/input/raid-dataset/test.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\n\n# 1. Load the CSV\ndf = pd.read_csv('/kaggle/input/raid-dataset/train.csv')\n\n# 2. Filter for human and GPT-4 rows\n#    (replace 'model' with whatever your column is called)\ndf_human = df[df['model'] == 'human']\ndf_gpt4  = df[df['model'] == 'gpt4']\n\n# 3. Sample 5000 from each (if you only need up to 5000, use min count)\nn = 5000\ndf_human_samp = df_human.sample(n=min(n, len(df_human)), random_state=42)\ndf_gpt4_samp  = df_gpt4.sample(n=min(n, len(df_gpt4)),   random_state=42)\n\n# 4. Combine and shuffle\ndf_sample = pd.concat([df_human_samp, df_gpt4_samp]).sample(frac=1, random_state=42).reset_index(drop=True)\n\nprint(df_sample.shape)   # should be (10000, …)\nprint(df_sample['model'].value_counts())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T00:20:20.969191Z","iopub.execute_input":"2025-06-12T00:20:20.969582Z","iopub.status.idle":"2025-06-12T00:24:49.877820Z","shell.execute_reply.started":"2025-06-12T00:20:20.969562Z","shell.execute_reply":"2025-06-12T00:24:49.877113Z"}},"outputs":[{"name":"stdout","text":"(10000, 11)\nmodel\ngpt4     5000\nhuman    5000\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# 2. Filter for human and GPT-4 rows\n#    (replace 'model' with whatever your column is called)\ndf_human = df[df['model'] == 'human']\ndf_gpt4  = df[df['model'] == 'gpt4']\ndf_chatgpt=df[df['model'] == 'chatgpt']\n\n# 3. Sample 5000 from each (if you only need up to 5000, use min count)\n\ndf_human_samp = df_human.sample(n=min(20000, len(df_human)), random_state=42)\ndf_gpt4_samp  = df_gpt4.sample(n=min(20000, len(df_gpt4)),   random_state=42)\ndf_chatgpt_samp  = df_chatgpt.sample(n=min(20000, len(df_chatgpt)),   random_state=42)\n\n# 4. Combine and shuffle\ndf_sample = pd.concat([df_human_samp, df_gpt4_samp,df_chatgpt_samp]).sample(frac=1, random_state=42).reset_index(drop=True)\n\nprint(df_sample.shape)   # should be (10000, …)\nprint(df_sample['model'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T00:28:31.177274Z","iopub.execute_input":"2025-06-12T00:28:31.178052Z","iopub.status.idle":"2025-06-12T00:28:32.538622Z","shell.execute_reply.started":"2025-06-12T00:28:31.178026Z","shell.execute_reply":"2025-06-12T00:28:32.537775Z"}},"outputs":[{"name":"stdout","text":"(60000, 11)\nmodel\nhuman      20000\ngpt4       20000\nchatgpt    20000\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# 1) Save the sampled DataFrame to CSV\ndf_sample.to_csv('sampled_train.csv', index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T00:28:56.525265Z","iopub.execute_input":"2025-06-12T00:28:56.525776Z","iopub.status.idle":"2025-06-12T00:29:00.261282Z","shell.execute_reply.started":"2025-06-12T00:28:56.525757Z","shell.execute_reply":"2025-06-12T00:29:00.260640Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/working/sampled_train.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T00:30:02.806163Z","iopub.execute_input":"2025-06-12T00:30:02.806754Z","iopub.status.idle":"2025-06-12T00:30:05.722538Z","shell.execute_reply.started":"2025-06-12T00:30:02.806729Z","shell.execute_reply":"2025-06-12T00:30:05.721997Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T00:30:08.290064Z","iopub.execute_input":"2025-06-12T00:30:08.290340Z","iopub.status.idle":"2025-06-12T00:30:08.481052Z","shell.execute_reply.started":"2025-06-12T00:30:08.290318Z","shell.execute_reply":"2025-06-12T00:30:08.480333Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                     id                         adv_source_id  \\\n0  56a0eb85-8d33-4b7c-96b1-edde193e3536  9351499c-21fd-4d94-906f-28cc40a6fbab   \n1  375ccfff-b83a-47a4-af50-d0c28e044f50  dbc75b18-0a96-47f5-b9d4-5e885f94dacb   \n2  90dce70c-1212-4e49-bd4b-9eee832048c0  d18cad56-11bf-4996-a22b-2b886c4bbef3   \n3  9e767500-0b0e-4e5b-9842-da4bf6812f75  757dc95e-18ef-4128-bcef-16028efe4202   \n4  570ddd69-e566-44f3-a314-96475fe55eaa  5bfe05cb-02aa-44d5-8b31-f827a1e6ef04   \n\n                              source_id  model  decoding repetition_penalty  \\\n0  9351499c-21fd-4d94-906f-28cc40a6fbab  human       NaN                NaN   \n1  ab5d1a0b-22a0-4933-9cb9-65026cd569b4   gpt4    greedy                 no   \n2  a48234f2-e5fb-471a-be2c-06500667b4e2   gpt4  sampling                 no   \n3  757dc95e-18ef-4128-bcef-16028efe4202  human       NaN                NaN   \n4  5bfe05cb-02aa-44d5-8b31-f827a1e6ef04  human       NaN                NaN   \n\n              attack     domain  \\\n0             number     reddit   \n1  insert_paragraphs     reddit   \n2   article_deletion       news   \n3  insert_paragraphs  abstracts   \n4             number      books   \n\n                                               title  \\\n0  My mom is shaming me for wanting to get off of...   \n1  DAE feel like their dreams make up memories? A...   \n2                    FBI agent colludes with analyst   \n3  Towards the effectiveness of Deep Convolutiona...   \n4                                              Helen   \n\n                                              prompt  \\\n0                                                NaN   \n1  Write just the body of a Reddit post titled \"D...   \n2  Write the body of a BBC news article titled \"F...   \n3                                                NaN   \n4                                                NaN   \n\n                                          generation  \n0  I have been medicated for ADHD and anxiety for...  \n1  I've been experiencing this strange phenomenon...  \n2  An FBI agent stands accused of colluding with ...  \n3  Deep Learning is considered to be a quite youn...  \n4   Helen tells the story of a young orphan, Hele...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>adv_source_id</th>\n      <th>source_id</th>\n      <th>model</th>\n      <th>decoding</th>\n      <th>repetition_penalty</th>\n      <th>attack</th>\n      <th>domain</th>\n      <th>title</th>\n      <th>prompt</th>\n      <th>generation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>56a0eb85-8d33-4b7c-96b1-edde193e3536</td>\n      <td>9351499c-21fd-4d94-906f-28cc40a6fbab</td>\n      <td>9351499c-21fd-4d94-906f-28cc40a6fbab</td>\n      <td>human</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>number</td>\n      <td>reddit</td>\n      <td>My mom is shaming me for wanting to get off of...</td>\n      <td>NaN</td>\n      <td>I have been medicated for ADHD and anxiety for...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>375ccfff-b83a-47a4-af50-d0c28e044f50</td>\n      <td>dbc75b18-0a96-47f5-b9d4-5e885f94dacb</td>\n      <td>ab5d1a0b-22a0-4933-9cb9-65026cd569b4</td>\n      <td>gpt4</td>\n      <td>greedy</td>\n      <td>no</td>\n      <td>insert_paragraphs</td>\n      <td>reddit</td>\n      <td>DAE feel like their dreams make up memories? A...</td>\n      <td>Write just the body of a Reddit post titled \"D...</td>\n      <td>I've been experiencing this strange phenomenon...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>90dce70c-1212-4e49-bd4b-9eee832048c0</td>\n      <td>d18cad56-11bf-4996-a22b-2b886c4bbef3</td>\n      <td>a48234f2-e5fb-471a-be2c-06500667b4e2</td>\n      <td>gpt4</td>\n      <td>sampling</td>\n      <td>no</td>\n      <td>article_deletion</td>\n      <td>news</td>\n      <td>FBI agent colludes with analyst</td>\n      <td>Write the body of a BBC news article titled \"F...</td>\n      <td>An FBI agent stands accused of colluding with ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9e767500-0b0e-4e5b-9842-da4bf6812f75</td>\n      <td>757dc95e-18ef-4128-bcef-16028efe4202</td>\n      <td>757dc95e-18ef-4128-bcef-16028efe4202</td>\n      <td>human</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>insert_paragraphs</td>\n      <td>abstracts</td>\n      <td>Towards the effectiveness of Deep Convolutiona...</td>\n      <td>NaN</td>\n      <td>Deep Learning is considered to be a quite youn...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>570ddd69-e566-44f3-a314-96475fe55eaa</td>\n      <td>5bfe05cb-02aa-44d5-8b31-f827a1e6ef04</td>\n      <td>5bfe05cb-02aa-44d5-8b31-f827a1e6ef04</td>\n      <td>human</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>number</td>\n      <td>books</td>\n      <td>Helen</td>\n      <td>NaN</td>\n      <td>Helen tells the story of a young orphan, Hele...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"df_main=df[[\"model\",\"title\",\"generation\"]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T00:34:09.768726Z","iopub.execute_input":"2025-06-12T00:34:09.769021Z","iopub.status.idle":"2025-06-12T00:34:09.779695Z","shell.execute_reply.started":"2025-06-12T00:34:09.769000Z","shell.execute_reply":"2025-06-12T00:34:09.779003Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"df_main[\"text\"]=df['title']+df['generation']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T00:34:48.109312Z","iopub.execute_input":"2025-06-12T00:34:48.109781Z","iopub.status.idle":"2025-06-12T00:34:48.179349Z","shell.execute_reply.started":"2025-06-12T00:34:48.109759Z","shell.execute_reply":"2025-06-12T00:34:48.178602Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/3475066341.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_main[\"text\"]=df['title']+df['generation']\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"df_main.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T00:34:54.787729Z","iopub.execute_input":"2025-06-12T00:34:54.788437Z","iopub.status.idle":"2025-06-12T00:34:54.796336Z","shell.execute_reply.started":"2025-06-12T00:34:54.788404Z","shell.execute_reply":"2025-06-12T00:34:54.795746Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"   model                                              title  \\\n0  human  My mom is shaming me for wanting to get off of...   \n1   gpt4  DAE feel like their dreams make up memories? A...   \n2   gpt4                    FBI agent colludes with analyst   \n3  human  Towards the effectiveness of Deep Convolutiona...   \n4  human                                              Helen   \n\n                                          generation  \\\n0  I have been medicated for ADHD and anxiety for...   \n1  I've been experiencing this strange phenomenon...   \n2  An FBI agent stands accused of colluding with ...   \n3  Deep Learning is considered to be a quite youn...   \n4   Helen tells the story of a young orphan, Hele...   \n\n                                                text  \n0  My mom is shaming me for wanting to get off of...  \n1  DAE feel like their dreams make up memories? A...  \n2  FBI agent colludes with analystAn FBI agent st...  \n3  Towards the effectiveness of Deep Convolutiona...  \n4  Helen Helen tells the story of a young orphan,...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>title</th>\n      <th>generation</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>human</td>\n      <td>My mom is shaming me for wanting to get off of...</td>\n      <td>I have been medicated for ADHD and anxiety for...</td>\n      <td>My mom is shaming me for wanting to get off of...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>gpt4</td>\n      <td>DAE feel like their dreams make up memories? A...</td>\n      <td>I've been experiencing this strange phenomenon...</td>\n      <td>DAE feel like their dreams make up memories? A...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>gpt4</td>\n      <td>FBI agent colludes with analyst</td>\n      <td>An FBI agent stands accused of colluding with ...</td>\n      <td>FBI agent colludes with analystAn FBI agent st...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>human</td>\n      <td>Towards the effectiveness of Deep Convolutiona...</td>\n      <td>Deep Learning is considered to be a quite youn...</td>\n      <td>Towards the effectiveness of Deep Convolutiona...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>human</td>\n      <td>Helen</td>\n      <td>Helen tells the story of a young orphan, Hele...</td>\n      <td>Helen Helen tells the story of a young orphan,...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"label_map={\n    'human':0,\n    'gpt4':1,\n    'chatgpt':1\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T00:37:37.351381Z","iopub.execute_input":"2025-06-12T00:37:37.351664Z","iopub.status.idle":"2025-06-12T00:37:37.355507Z","shell.execute_reply.started":"2025-06-12T00:37:37.351645Z","shell.execute_reply":"2025-06-12T00:37:37.354721Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"df_main['model']=df_main['model'].map(label_map);","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T00:38:11.745849Z","iopub.execute_input":"2025-06-12T00:38:11.746542Z","iopub.status.idle":"2025-06-12T00:38:11.757709Z","shell.execute_reply.started":"2025-06-12T00:38:11.746512Z","shell.execute_reply":"2025-06-12T00:38:11.756915Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/946050259.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_main['model']=df_main['model'].map(label_map);\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"df=df_main[[\"model\",\"text\"]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T00:45:39.965543Z","iopub.execute_input":"2025-06-12T00:45:39.966263Z","iopub.status.idle":"2025-06-12T00:45:39.975465Z","shell.execute_reply.started":"2025-06-12T00:45:39.966242Z","shell.execute_reply":"2025-06-12T00:45:39.974569Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"## stage 1","metadata":{}},{"cell_type":"code","source":"import re\nimport string\nimport pandas as pd\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.tokenize import word_tokenize\n\n# If you haven’t already:\n# import nltk\n# nltk.download('punkt')\n# nltk.download('stopwords')\n\nstop_words = set(stopwords.words('english'))\nstemmer    = PorterStemmer()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T00:45:54.106798Z","iopub.execute_input":"2025-06-12T00:45:54.107309Z","iopub.status.idle":"2025-06-12T00:45:54.111633Z","shell.execute_reply.started":"2025-06-12T00:45:54.107283Z","shell.execute_reply":"2025-06-12T00:45:54.111050Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def preprocess_text(text):\n    # 1. Replace URLs, hashtags, mentions, numbers, currency\n    text = re.sub(r'http\\S+|www\\.\\S+', 'HTTPADDR', text)\n    text = re.sub(r'#\\w+', 'HSTIDS', text)\n    text = re.sub(r'@\\w+', 'USERID', text)\n    text = re.sub(r'\\d+', 'NUMIDS', text)\n    text = re.sub(r'[€£\\$]', 'CURRIDS', text)\n    # 2. Drop non-ASCII (emojis, non-alphabetic punctuation)\n    text = text.encode('ascii', errors='ignore').decode()\n    # 3. Remove punctuation\n    text = text.translate(str.maketrans('', '', string.punctuation))\n    # 4. Tokenize & lowercase\n    tokens = word_tokenize(text.lower())\n    # 5. Remove stop-words & stem\n    tokens = [stemmer.stem(tok) for tok in tokens if tok not in stop_words]\n    return tokens\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T00:45:59.640576Z","iopub.execute_input":"2025-06-12T00:45:59.640837Z","iopub.status.idle":"2025-06-12T00:45:59.646064Z","shell.execute_reply.started":"2025-06-12T00:45:59.640817Z","shell.execute_reply":"2025-06-12T00:45:59.645314Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Assume df is already loaded, with columns 'text' and 'model'\ndf['tokens'] = df['text'].map(preprocess_text)\n# Quick sanity-check\nprint(df[['text','tokens']].head(3))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T00:46:06.075127Z","iopub.execute_input":"2025-06-12T00:46:06.075404Z","iopub.status.idle":"2025-06-12T00:49:05.424746Z","shell.execute_reply.started":"2025-06-12T00:46:06.075382Z","shell.execute_reply":"2025-06-12T00:49:05.423969Z"}},"outputs":[{"name":"stdout","text":"                                                text  \\\n0  My mom is shaming me for wanting to get off of...   \n1  DAE feel like their dreams make up memories? A...   \n2  FBI agent colludes with analystAn FBI agent st...   \n\n                                              tokens  \n0  [mom, shame, want, get, medic, instead, go, wa...  \n1  [dae, feel, like, dream, make, memori, cant, t...  \n2  [fbi, agent, collud, analystan, fbi, agent, st...  \n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_35/2073079088.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df['tokens'] = df['text'].map(preprocess_text)\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"from collections import Counter\n\n# Flatten all token lists into one big list\nall_tokens = [tok for tokens in df['tokens'] for tok in tokens]\nfreq_map   = Counter(all_tokens)\n\n# Inspect the 10 most common & 10 rarest words\nprint(\"Most common:\", freq_map.most_common(10))\nrare = [w for w, c in freq_map.items() if c == 1]\nprint(\"A few words with freq=1:\", rare[:10])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T00:49:05.425904Z","iopub.execute_input":"2025-06-12T00:49:05.426177Z","iopub.status.idle":"2025-06-12T00:49:07.201558Z","shell.execute_reply.started":"2025-06-12T00:49:05.426158Z","shell.execute_reply":"2025-06-12T00:49:07.200776Z"}},"outputs":[{"name":"stdout","text":"Most common: [('numid', 206108), ('th', 91620), ('n', 54717), ('nd', 53078), ('f', 45438), ('numidsnumid', 45328), ('also', 30650), ('cup', 30536), ('one', 29143), ('time', 26349)]\nA few words with freq=1: ['mmnttng', 'furycaptain', 'heartgrip', 'duallevel', 'zkr', 'sglk', 'rhthmst', 'ndss', 'flatsnumid', 'setswhil']\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"RARE_THRESHOLD = 10\ndef replace_rare(tokens):\n    return [tok if freq_map[tok] >= RARE_THRESHOLD else 'rareWord'\n            for tok in tokens]\n\ndf['tokens'] = df['tokens'].map(replace_rare)\n# Check again\nprint(df[['tokens']].head(3))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T00:49:19.051413Z","iopub.execute_input":"2025-06-12T00:49:19.051671Z","iopub.status.idle":"2025-06-12T00:49:21.222987Z","shell.execute_reply.started":"2025-06-12T00:49:19.051653Z","shell.execute_reply":"2025-06-12T00:49:21.222240Z"}},"outputs":[{"name":"stdout","text":"                                              tokens\n0  [mom, shame, want, get, medic, instead, go, wa...\n1  [dae, feel, like, dream, make, memori, cant, t...\n2  [fbi, agent, collud, rareWord, fbi, agent, sta...\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_35/2439514293.py:6: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df['tokens'] = df['tokens'].map(replace_rare)\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"df.to_csv(\"stage1.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T00:51:43.362799Z","iopub.execute_input":"2025-06-12T00:51:43.363501Z","iopub.status.idle":"2025-06-12T00:51:49.861336Z","shell.execute_reply.started":"2025-06-12T00:51:43.363476Z","shell.execute_reply":"2025-06-12T00:51:49.860513Z"}},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":"## stage 2\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming df has columns 'tokens' and 'model' (0=human, 1=AI)\nn = 5000\n\n# 1. Sample 5 000 from each class\ndf0 = df[df['model'] == 0].sample(n=min(n, len(df[df['model']==0])), random_state=42)\ndf1 = df[df['model'] == 1].sample(n=min(n, len(df[df['model']==1])), random_state=42)\n\n# 2. Combine & shuffle\ndf_sub = pd.concat([df0, df1]).sample(frac=1, random_state=42).reset_index(drop=True)\n\nprint(\"Subset shape:\", df_sub.shape)\nprint(df_sub['model'].value_counts())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T00:54:30.638004Z","iopub.execute_input":"2025-06-12T00:54:30.638668Z","iopub.status.idle":"2025-06-12T00:54:30.674583Z","shell.execute_reply.started":"2025-06-12T00:54:30.638639Z","shell.execute_reply":"2025-06-12T00:54:30.674007Z"}},"outputs":[{"name":"stdout","text":"Subset shape: (10000, 3)\nmodel\n1    5000\n0    5000\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n# We need a string corpus—join each token list into space-separated text\ncorpus = [\" \".join(tokens) for tokens in df_sub['tokens']]\n\n# Fit TF–IDF on the full corpus (IDF only)\n# 4. Fit a new TF–IDF on just the subset\ntfidf_vec_sub = TfidfVectorizer(max_features=50000)\ntfidf_vec_sub.fit(corpus)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T00:56:02.568776Z","iopub.execute_input":"2025-06-12T00:56:02.569341Z","iopub.status.idle":"2025-06-12T00:56:03.761840Z","shell.execute_reply.started":"2025-06-12T00:56:02.569317Z","shell.execute_reply":"2025-06-12T00:56:03.761098Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"TfidfVectorizer(max_features=50000)","text/html":"<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_features=50000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=50000)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"import numpy as np\n\n# Parameters\nMAX_VOCAB_SIZE = 48   # number of tokens per tweet to keep\nEPS = 1e-8            # small constant for division\n\ndef build_cooccurrence_matrix(tokens, tfidf_vec):\n    \"\"\"\n    tokens: list of preprocessed tokens for one tweet\n    tfidf_vec: fitted TfidfVectorizer\n    Returns: M×M numpy array, where M = MAX_VOCAB_SIZE\n    \"\"\"\n    # 1. Select up to M unique tokens, preserving order\n    uniq = []\n    for t in tokens:\n        if t not in uniq:\n            uniq.append(t)\n        if len(uniq) >= MAX_VOCAB_SIZE:\n            break\n    # Pad with a special token if needed\n    while len(uniq) < MAX_VOCAB_SIZE:\n        uniq.append('<PAD>')\n\n    # 2. Compute TF–IDF vector for this tweet over our vocab\n    text = \" \".join(tokens)\n    tfidf_row = tfidf_vec.transform([text]).toarray()[0]  # shape (V_full,)\n    # Extract the TF–IDF values for our uniq tokens\n    idf_vals = np.array([ tfidf_row[ tfidf_vec.vocabulary_.get(w, -1) ] \n                          if w in tfidf_vec.vocabulary_ else 0.0\n                          for w in uniq ])\n\n    # 3. Count frequencies in the tweet\n    freq = {w: tokens.count(w) for w in uniq}\n\n    # 4. Build M×M matrix\n    M = MAX_VOCAB_SIZE\n    mat = np.zeros((M, M), dtype=float)\n    # Diagonal ← TF–IDF\n    for i in range(M):\n        mat[i, i] = idf_vals[i]\n\n    # Off-diagonals\n    for i in range(M):\n        for j in range(M):\n            if i == j:\n                continue\n            # co-occurrence count\n            cooc = 1 if (freq.get(uniq[i], 0) > 0 and freq.get(uniq[j],0) > 0) else 0\n            if i > j:\n                mat[i, j] = cooc\n            else:  # i < j, normalized “correlation”\n                denom = freq.get(uniq[i],0) * freq.get(uniq[j],0) + EPS\n                mat[i, j] = cooc / denom\n\n    return mat\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T01:01:31.864164Z","iopub.execute_input":"2025-06-12T01:01:31.865290Z","iopub.status.idle":"2025-06-12T01:01:31.873366Z","shell.execute_reply.started":"2025-06-12T01:01:31.865235Z","shell.execute_reply":"2025-06-12T01:01:31.872664Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"# Example: build and store the matrix for the first tweet\nexample_mat = build_cooccurrence_matrix(df.loc[0, 'tokens'], tfidf_vec)\nprint(\"Shape:\", example_mat.shape)\nprint(example_mat)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T01:01:33.000167Z","iopub.execute_input":"2025-06-12T01:01:33.000450Z","iopub.status.idle":"2025-06-12T01:01:33.010519Z","shell.execute_reply.started":"2025-06-12T01:01:33.000431Z","shell.execute_reply":"2025-06-12T01:01:33.009798Z"}},"outputs":[{"name":"stdout","text":"Shape: (48, 48)\n[[0.27441466 0.33333333 0.16666667 ... 0.16666667 0.33333333 0.33333333]\n [1.         0.0923223  0.5        ... 0.5        0.99999999 0.99999999]\n [1.         1.         0.09663782 ... 0.25       0.5        0.5       ]\n ...\n [1.         1.         1.         ... 0.10805361 0.5        0.5       ]\n [1.         1.         1.         ... 1.         0.05201217 0.99999999]\n [1.         1.         1.         ... 1.         1.         0.07235461]]\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"# Pre-allocate and build\nN_sub = len(df_sub)\nM = MAX_VOCAB_SIZE\nmatrices_sub = np.zeros((N_sub, M, M), dtype=float)\n\nfor idx, tokens in enumerate(df_sub['tokens']):\n    matrices_sub[idx] = build_cooccurrence_matrix(tokens, tfidf_vec_sub)\n    if idx % 1000 == 0:\n        print(f\"[{idx}/{N_sub}] matrices built\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T01:01:36.087173Z","iopub.execute_input":"2025-06-12T01:01:36.087449Z","iopub.status.idle":"2025-06-12T01:01:58.338458Z","shell.execute_reply.started":"2025-06-12T01:01:36.087429Z","shell.execute_reply":"2025-06-12T01:01:58.337856Z"}},"outputs":[{"name":"stdout","text":"[0/10000] matrices built\n[1000/10000] matrices built\n[2000/10000] matrices built\n[3000/10000] matrices built\n[4000/10000] matrices built\n[5000/10000] matrices built\n[6000/10000] matrices built\n[7000/10000] matrices built\n[8000/10000] matrices built\n[9000/10000] matrices built\n","output_type":"stream"}],"execution_count":48},{"cell_type":"markdown","source":"## Stage 3","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\n\nclass MatrixDataset(Dataset):\n    def __init__(self, matrices):\n        # matrices: np.array of shape (N, M, M)\n        self.mats = torch.from_numpy(matrices).float().unsqueeze(1)  # → (N,1,M,M)\n\n    def __len__(self):\n        return self.mats.size(0)\n\n    def __getitem__(self, idx):\n        return self.mats[idx]\n\n# Replace `matrices_sub` with your array; choose batch_size=4 as in paper\ndataset = MatrixDataset(matrices_sub)\nloader  = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=2, drop_last=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T01:02:10.730353Z","iopub.execute_input":"2025-06-12T01:02:10.730625Z","iopub.status.idle":"2025-06-12T01:02:10.787221Z","shell.execute_reply.started":"2025-06-12T01:02:10.730604Z","shell.execute_reply":"2025-06-12T01:02:10.786596Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"import torch.nn as nn\n\nclass UNetGenerator(nn.Module):\n    def __init__(self, in_ch=1, ngf=64):\n        super().__init__()\n        # Encoder (downsamples by 2 each layer)\n        self.enc1 = nn.Sequential(nn.Conv2d(in_ch,    ngf, 4, 2, 1),\n                                   nn.BatchNorm2d(ngf), nn.LeakyReLU(0.2))\n        self.enc2 = nn.Sequential(nn.Conv2d(ngf,  ngf*2, 4, 2, 1),\n                                   nn.BatchNorm2d(ngf*2), nn.LeakyReLU(0.2))\n        self.enc3 = nn.Sequential(nn.Conv2d(ngf*2,ngf*4, 4, 2, 1),\n                                   nn.BatchNorm2d(ngf*4), nn.LeakyReLU(0.2))\n        self.enc4 = nn.Sequential(nn.Conv2d(ngf*4,ngf*8, 4, 2, 1),\n                                   nn.BatchNorm2d(ngf*8), nn.LeakyReLU(0.2))\n        # Decoder (upsamples by 2 each layer, with skip-connections)\n        self.dec1 = nn.Sequential(nn.ConvTranspose2d(ngf*8,   ngf*4, 4, 2, 1),\n                                   nn.BatchNorm2d(ngf*4), nn.ReLU())\n        self.dec2 = nn.Sequential(nn.ConvTranspose2d(ngf*8,   ngf*2, 4, 2, 1),\n                                   nn.BatchNorm2d(ngf*2), nn.ReLU())\n        self.dec3 = nn.Sequential(nn.ConvTranspose2d(ngf*4,     ngf, 4, 2, 1),\n                                   nn.BatchNorm2d(ngf),   nn.ReLU())\n        self.dec4 = nn.Sequential(nn.ConvTranspose2d(ngf*2, in_ch, 4, 2, 1),\n                                   nn.Tanh())\n\n    def forward(self, x):\n        e1 = self.enc1(x)              # → [B, ngf,    M/2,   M/2]\n        e2 = self.enc2(e1)             # → [B,2ngf,   M/4,   M/4]\n        e3 = self.enc3(e2)             # → [B,4ngf,   M/8,   M/8]\n        e4 = self.enc4(e3)             # → [B,8ngf,   M/16,  M/16]\n        d1 = self.dec1(e4)             \n        d2 = self.dec2(torch.cat([d1, e3], dim=1))\n        d3 = self.dec3(torch.cat([d2, e2], dim=1))\n        d4 = self.dec4(torch.cat([d3, e1], dim=1))\n        return d4, d3  # d4: reconstructed matrix; d3: feature map\n\n\nclass Discriminator(nn.Module):\n    def __init__(self, in_ch=1, ndf=64):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Conv2d(in_ch,   ndf,   4, 2, 1), nn.BatchNorm2d(ndf),   nn.LeakyReLU(0.2),\n            nn.Conv2d(ndf,    ndf*2,  4, 2, 1), nn.BatchNorm2d(ndf*2), nn.LeakyReLU(0.2),\n            nn.Conv2d(ndf*2,  ndf*4,  4, 2, 1), nn.BatchNorm2d(ndf*4), nn.LeakyReLU(0.2),\n            nn.Conv2d(ndf*4,     1,   4, 1, 0)                      # → [B,1,1,1]\n        )\n\n    def forward(self, x):\n        return self.net(x).view(-1)  # flatten to [B]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T01:02:11.235118Z","iopub.execute_input":"2025-06-12T01:02:11.235363Z","iopub.status.idle":"2025-06-12T01:02:11.247681Z","shell.execute_reply.started":"2025-06-12T01:02:11.235346Z","shell.execute_reply":"2025-06-12T01:02:11.247110Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"import torch.autograd as autograd\n\ndef gradient_penalty(D, real, fake, device):\n    B = real.size(0)\n    alpha = torch.rand(B, 1, 1, 1, device=device)\n    interp = (alpha * real + (1-alpha) * fake).requires_grad_(True)\n    d_interp = D(interp)\n    grads = autograd.grad(outputs=d_interp, inputs=interp,\n                          grad_outputs=torch.ones_like(d_interp),\n                          create_graph=True, retain_graph=True)[0]\n    grads = grads.view(B, -1)\n    return ((grads.norm(2, dim=1) - 1)**2).mean()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T01:02:11.787792Z","iopub.execute_input":"2025-06-12T01:02:11.788099Z","iopub.status.idle":"2025-06-12T01:02:11.792967Z","shell.execute_reply.started":"2025-06-12T01:02:11.788078Z","shell.execute_reply":"2025-06-12T01:02:11.792407Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"import torch.optim as optim\nimport torch.nn.functional as F\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nG = UNetGenerator().to(device)\nD = Discriminator().to(device)\n\noptG = optim.Adam(G.parameters(), lr=1e-4, betas=(0.5, 0.9))\noptD = optim.Adam(D.parameters(), lr=1e-4, betas=(0.5, 0.9))\n\nlambda_gp = 10    # WGAN-GP gradient penalty weight\nlambda_l1 = 100   # L1 reconstruction loss weight\nn_epochs  = 30    # start smaller; increase if needed\n\nfor epoch in range(1, n_epochs+1):\n    for real in loader:\n        real = real.to(device)\n\n        # ——— Discriminator step ———\n        fake, _ = G(real + 0.01*torch.randn_like(real))  # small input noise\n        d_real = D(real)\n        d_fake = D(fake.detach())\n        gp     = gradient_penalty(D, real, fake.detach(), device)\n        lossD  = -(d_real.mean() - d_fake.mean()) + lambda_gp * gp\n\n        optD.zero_grad()\n        lossD.backward()\n        optD.step()\n\n        # ——— Generator step ———\n        fake, _   = G(real)\n        lossG_adv = -D(fake).mean()\n        lossG_l1  = F.l1_loss(fake, real) * lambda_l1\n        lossG     = lossG_adv + lossG_l1\n\n        optG.zero_grad()\n        lossG.backward()\n        optG.step()\n\n    print(f\"[Epoch {epoch}/{n_epochs}]  lossD: {lossD.item():.4f}  lossG: {lossG.item():.4f}\")\n\n    # Optional: save checkpoints every few epochs\n    if epoch % 10 == 0:\n        torch.save(G.state_dict(), f'G_epoch{epoch}.pth')\n        torch.save(D.state_dict(), f'D_epoch{epoch}.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T01:02:12.446601Z","iopub.execute_input":"2025-06-12T01:02:12.447204Z","iopub.status.idle":"2025-06-12T01:36:58.294728Z","shell.execute_reply.started":"2025-06-12T01:02:12.447181Z","shell.execute_reply":"2025-06-12T01:36:58.293686Z"}},"outputs":[{"name":"stdout","text":"[Epoch 1/30]  lossD: -1.3588  lossG: 3.5561\n[Epoch 2/30]  lossD: -1.5622  lossG: 2.0235\n[Epoch 3/30]  lossD: -2.5503  lossG: 1.3811\n[Epoch 4/30]  lossD: -0.2104  lossG: 1.7168\n[Epoch 5/30]  lossD: -0.3239  lossG: 1.3917\n[Epoch 6/30]  lossD: 0.0055  lossG: 0.5474\n[Epoch 7/30]  lossD: -0.0016  lossG: 0.3533\n[Epoch 8/30]  lossD: 0.0169  lossG: 0.0732\n[Epoch 9/30]  lossD: -0.0018  lossG: 0.2214\n[Epoch 10/30]  lossD: -0.0068  lossG: 0.1156\n[Epoch 11/30]  lossD: -0.0115  lossG: 0.8125\n[Epoch 12/30]  lossD: -0.0055  lossG: 0.3588\n[Epoch 13/30]  lossD: 0.0010  lossG: 0.4361\n[Epoch 14/30]  lossD: -0.0024  lossG: 0.7324\n[Epoch 15/30]  lossD: -0.0044  lossG: 0.8194\n[Epoch 16/30]  lossD: -0.0017  lossG: 1.0061\n[Epoch 17/30]  lossD: -0.0027  lossG: 1.4455\n[Epoch 18/30]  lossD: -0.0110  lossG: 1.3118\n[Epoch 19/30]  lossD: -0.0043  lossG: 1.3177\n[Epoch 20/30]  lossD: -0.0032  lossG: 1.2204\n[Epoch 21/30]  lossD: -0.0031  lossG: 1.5761\n[Epoch 22/30]  lossD: -0.0028  lossG: 1.7660\n[Epoch 23/30]  lossD: -0.0076  lossG: 1.8535\n[Epoch 24/30]  lossD: -0.0063  lossG: 1.8167\n[Epoch 25/30]  lossD: -0.0039  lossG: 2.0525\n[Epoch 26/30]  lossD: 0.0027  lossG: 2.0133\n[Epoch 27/30]  lossD: -0.0037  lossG: 2.3384\n[Epoch 28/30]  lossD: -0.0053  lossG: 2.0505\n[Epoch 29/30]  lossD: -0.0028  lossG: 2.2983\n[Epoch 30/30]  lossD: -0.0042  lossG: 2.3362\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"# If you saved checkpoints, load the final or best one:\nG.load_state_dict(torch.load('G_epoch30.pth', map_location=device))\nG.eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T01:37:21.669919Z","iopub.execute_input":"2025-06-12T01:37:21.670494Z","iopub.status.idle":"2025-06-12T01:37:21.710419Z","shell.execute_reply.started":"2025-06-12T01:37:21.670463Z","shell.execute_reply":"2025-06-12T01:37:21.709851Z"}},"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"UNetGenerator(\n  (enc1): Sequential(\n    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): LeakyReLU(negative_slope=0.2)\n  )\n  (enc2): Sequential(\n    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): LeakyReLU(negative_slope=0.2)\n  )\n  (enc3): Sequential(\n    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): LeakyReLU(negative_slope=0.2)\n  )\n  (enc4): Sequential(\n    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): LeakyReLU(negative_slope=0.2)\n  )\n  (dec1): Sequential(\n    (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n  )\n  (dec2): Sequential(\n    (0): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n  )\n  (dec3): Sequential(\n    (0): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n  )\n  (dec4): Sequential(\n    (0): ConvTranspose2d(128, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (1): Tanh()\n  )\n)"},"metadata":{}}],"execution_count":53},{"cell_type":"code","source":"# Grab a single batch\nmats, idxs = next(iter(idx_loader))\nmats = mats.to(device)\nwith torch.no_grad():\n    _, d3 = G(mats)\nB, C, H, W = d3.shape\nfeat_dim = C * H * W\nprint(\"Detected feature dimension:\", feat_dim)  # e.g. 16384\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T01:39:06.180618Z","iopub.execute_input":"2025-06-12T01:39:06.181519Z","iopub.status.idle":"2025-06-12T01:39:06.664192Z","shell.execute_reply.started":"2025-06-12T01:39:06.181478Z","shell.execute_reply":"2025-06-12T01:39:06.663352Z"}},"outputs":[{"name":"stdout","text":"Detected feature dimension: 36864\n","output_type":"stream"}],"execution_count":55},{"cell_type":"markdown","source":"## stage 4","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom tqdm.auto import tqdm\n\n# 4.1. Prepare an indexed dataset for matrices_sub\nclass IndexedMatrixDataset(Dataset):\n    def __init__(self, matrices):\n        # matrices: NumPy array of shape (N, M, M)\n        self.mats = torch.from_numpy(matrices).float().unsqueeze(1)  # → (N,1,M,M)\n\n    def __len__(self):\n        return self.mats.size(0)\n\n    def __getitem__(self, idx):\n        return self.mats[idx], idx\n\n# Create loader (no shuffle so idxs line up)\nidx_ds = IndexedMatrixDataset(matrices_sub)\nidx_loader = DataLoader(idx_ds, batch_size=16, shuffle=False, num_workers=2)\n\n# 4.2. Ensure your Generator is in eval mode and on the correct device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nG.eval()\nG.to(device)\n\n# 4.3. Infer feat_dim from one batch\nwith torch.no_grad():\n    sample_mats, sample_idxs = next(iter(idx_loader))\n    sample_mats = sample_mats.to(device)\n    _, sample_d3 = G(sample_mats)        # sample_d3 shape: [B, C, H, W]\n    B, C, H, W = sample_d3.shape\n    feat_dim = C * H * W\n    print(f\"Inferred feature dimension: C={C}, H={H}, W={W} → feat_dim={feat_dim}\")\n\n# 4.4. Allocate the features array\nN = len(idx_ds)\nfeatures = np.zeros((N, feat_dim), dtype=np.float32)\n\n# 4.5. Extract and store features\nwith torch.no_grad():\n    for mats, idxs in tqdm(idx_loader, desc=\"Extracting GAN features\"):\n        mats = mats.to(device)\n        _, d3 = G(mats)                     # d3: [B, C, H, W]\n        flat = d3.view(d3.size(0), -1).cpu().numpy()  # → [B, feat_dim]\n        for i, orig_idx in enumerate(idxs):\n            features[orig_idx] = flat[i]\n\n# Now `features` is an (N, feat_dim) array of your GAN-based representations\n# You can proceed to Stage 5: Random Forest training with `features` and your labels.\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T01:40:19.628087Z","iopub.execute_input":"2025-06-12T01:40:19.628427Z","iopub.status.idle":"2025-06-12T01:40:28.396309Z","shell.execute_reply.started":"2025-06-12T01:40:19.628392Z","shell.execute_reply":"2025-06-12T01:40:28.395101Z"}},"outputs":[{"name":"stdout","text":"Inferred feature dimension: C=64, H=24, W=24 → feat_dim=36864\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Extracting GAN features:   0%|          | 0/625 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"495ffa540b124e029913e88a91853159"}},"metadata":{}}],"execution_count":56},{"cell_type":"markdown","source":"## stage 5","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# `features` is shape (N, feat_dim); `df_sub['model']` holds 0/1 labels\nX = features\ny = df_sub['model'].values\n\n# 80/20 stratified split\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size=0.2, stratify=y, random_state=42\n)\n\nprint(\"Training set:\", X_train.shape, y_train.shape)\nprint(\"Validation set:\", X_val.shape, y_val.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T01:41:01.905713Z","iopub.execute_input":"2025-06-12T01:41:01.906225Z","iopub.status.idle":"2025-06-12T01:41:02.983733Z","shell.execute_reply.started":"2025-06-12T01:41:01.906186Z","shell.execute_reply":"2025-06-12T01:41:02.982983Z"}},"outputs":[{"name":"stdout","text":"Training set: (8000, 36864) (8000,)\nValidation set: (2000, 36864) (2000,)\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nimport numpy as np\n\n# 1) Train a standard Random Forest\nrf = RandomForestClassifier(\n    n_estimators=100,      # number of trees\n    oob_score=True,        # enable out-of-bag scoring\n    n_jobs=-1,             # use all cores\n    random_state=42\n)\nrf.fit(X_train, y_train)\n\n# 2) Compute each tree’s accuracy on the training set (or OOB samples)\ntree_weights = []\nfor tree in rf.estimators_:\n    preds = tree.predict(X_train)\n    acc   = accuracy_score(y_train, preds)\n    tree_weights.append(acc)\n\ntree_weights = np.array(tree_weights)\ntree_weights = tree_weights / tree_weights.sum()   # normalize to sum = 1\n\nprint(\"Computed tree weights. Sample:\", tree_weights[:5])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T01:41:12.282227Z","iopub.execute_input":"2025-06-12T01:41:12.282508Z","iopub.status.idle":"2025-06-12T01:42:40.259003Z","shell.execute_reply.started":"2025-06-12T01:41:12.282487Z","shell.execute_reply":"2025-06-12T01:42:40.258344Z"}},"outputs":[{"name":"stdout","text":"Computed tree weights. Sample: [0.00998749 0.01008257 0.01004246 0.00995778 0.01004543]\n","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"def weighted_rf_predict(rf, tree_weights, X):\n    \"\"\"\n    rf           : trained RandomForestClassifier\n    tree_weights: array of shape (n_estimators,) summing to 1\n    X            : feature array (n_samples, feat_dim)\n\n    Returns:\n      y_pred (n_samples,) binary predictions,\n      y_prob (n_samples,) weighted probability of class 1\n    \"\"\"\n    # Initialize probability accumulator\n    probs = np.zeros(X.shape[0], dtype=float)\n\n    # Accumulate each tree’s predicted probability for class 1, weighted\n    for w, tree in zip(tree_weights, rf.estimators_):\n        probs += w * tree.predict_proba(X)[:, 1]\n\n    # Binary decision at 0.5 threshold\n    y_pred = (probs >= 0.5).astype(int)\n    return y_pred, probs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T01:42:51.062888Z","iopub.execute_input":"2025-06-12T01:42:51.063803Z","iopub.status.idle":"2025-06-12T01:42:51.068170Z","shell.execute_reply.started":"2025-06-12T01:42:51.063769Z","shell.execute_reply":"2025-06-12T01:42:51.067523Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"from sklearn.metrics import classification_report, roc_auc_score\n\n# Get predictions\ny_pred, y_prob = weighted_rf_predict(rf, tree_weights, X_val)\n\n# Classification metrics\nprint(classification_report(y_val, y_pred, digits=4))\n\n# AUC\nauc = roc_auc_score(y_val, y_prob)\nprint(f\"Validation AUC: {auc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T01:43:22.610594Z","iopub.execute_input":"2025-06-12T01:43:22.611175Z","iopub.status.idle":"2025-06-12T01:43:26.075622Z","shell.execute_reply.started":"2025-06-12T01:43:22.611149Z","shell.execute_reply":"2025-06-12T01:43:26.075000Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.6813    0.6990    0.6900      1000\n           1     0.6910    0.6730    0.6819      1000\n\n    accuracy                         0.6860      2000\n   macro avg     0.6861    0.6860    0.6859      2000\nweighted avg     0.6861    0.6860    0.6859      2000\n\nValidation AUC: 0.7650\n","output_type":"stream"}],"execution_count":60},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\nskf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\nmetrics = {'acc': [], 'prec': [], 'rec': [], 'f1': [], 'auc': []}\n\nfor train_idx, val_idx in skf.split(X, y):\n    X_tr, X_va = X[train_idx], X[val_idx]\n    y_tr, y_va = y[train_idx], y[val_idx]\n\n    # Train RF\n    rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n    rf.fit(X_tr, y_tr)\n\n    # Compute tree weights on training set\n    tw = []\n    for tree in rf.estimators_:\n        pred_tr = tree.predict(X_tr)\n        tw.append(accuracy_score(y_tr, pred_tr))\n    tw = np.array(tw)\n    tw = tw / tw.sum()\n\n    # Predict on validation fold\n    y_va_pred, y_va_prob = weighted_rf_predict(rf, tw, X_va)\n\n    # Record metrics\n    metrics['acc'].append(accuracy_score(y_va, y_va_pred))\n    metrics['prec'].append(precision_score(y_va, y_va_pred))\n    metrics['rec'].append(recall_score(y_va, y_va_pred))\n    metrics['f1'].append(f1_score(y_va, y_va_pred))\n    metrics['auc'].append(roc_auc_score(y_va, y_va_prob))\n\n# Print average and std\nfor m in metrics:\n    vals = metrics[m]\n    print(f\"{m.upper()}: {np.mean(vals):.4f} ± {np.std(vals):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T01:43:45.038726Z","iopub.execute_input":"2025-06-12T01:43:45.039452Z","iopub.status.idle":"2025-06-12T01:54:36.283139Z","shell.execute_reply.started":"2025-06-12T01:43:45.039427Z","shell.execute_reply":"2025-06-12T01:54:36.282412Z"}},"outputs":[{"name":"stdout","text":"ACC: 0.6709 ± 0.0115\nPREC: 0.6747 ± 0.0125\nREC: 0.6602 ± 0.0128\nF1: 0.6673 ± 0.0116\nAUC: 0.7471 ± 0.0137\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"from sklearn.metrics import (\n    accuracy_score,\n    precision_score,\n    recall_score,\n    f1_score,\n    roc_auc_score,\n    confusion_matrix,\n    classification_report\n)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# 1) Get your predictions & probabilities\ny_pred, y_prob = weighted_rf_predict(rf, tree_weights, X_val)\n\n# 2) Compute metrics\nacc   = accuracy_score(y_val, y_pred)\nprec  = precision_score(y_val, y_pred)\nrec   = recall_score(y_val, y_pred)\nf1    = f1_score(y_val, y_pred)\nauc   = roc_auc_score(y_val, y_prob)\n\nprint(f\"Accuracy : {acc:.4f}\")\nprint(f\"Precision: {prec:.4f}\")\nprint(f\"Recall   : {rec:.4f}\")\nprint(f\"F1-score : {f1:.4f}\")\nprint(f\"AUC      : {auc:.4f}\\n\")\n\n# 3) Full classification report (includes support)\nprint(\"Classification Report:\\n\")\nprint(classification_report(y_val, y_pred, digits=4))\n\n# 4) Confusion matrix\ncm = confusion_matrix(y_val, y_pred)\nplt.figure(figsize=(4,3))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", \n            xticklabels=[0,1], yticklabels=[0,1])\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T01:54:36.284157Z","iopub.execute_input":"2025-06-12T01:54:36.284385Z","iopub.status.idle":"2025-06-12T01:54:40.132356Z","shell.execute_reply.started":"2025-06-12T01:54:36.284368Z","shell.execute_reply":"2025-06-12T01:54:40.131608Z"}},"outputs":[{"name":"stdout","text":"Accuracy : 0.9670\nPrecision: 0.9670\nRecall   : 0.9670\nF1-score : 0.9670\nAUC      : 0.9978\n\nClassification Report:\n\n              precision    recall  f1-score   support\n\n           0     0.9670    0.9670    0.9670      1000\n           1     0.9670    0.9670    0.9670      1000\n\n    accuracy                         0.9670      2000\n   macro avg     0.9670    0.9670    0.9670      2000\nweighted avg     0.9670    0.9670    0.9670      2000\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 400x300 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":62},{"cell_type":"code","source":"# Baseline (unweighted) RF\ny_pred_base = rf.predict(X_val)\nacc_base  = accuracy_score(y_val, y_pred_base)\nauc_base  = roc_auc_score(y_val, rf.predict_proba(X_val)[:,1])\nprint(f\"Baseline RF →  Acc: {acc_base:.4f}, AUC: {auc_base:.4f}\")\n\n# Weighted RF\ny_pred_w, y_prob_w = weighted_rf_predict(rf, tree_weights, X_val)\nacc_w  = accuracy_score(y_val, y_pred_w)\nauc_w  = roc_auc_score(y_val, y_prob_w)\nprint(f\"Weighted RF →  Acc: {acc_w:.4f}, AUC: {auc_w:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T01:56:48.213406Z","iopub.execute_input":"2025-06-12T01:56:48.213989Z","iopub.status.idle":"2025-06-12T01:56:51.819246Z","shell.execute_reply.started":"2025-06-12T01:56:48.213941Z","shell.execute_reply":"2025-06-12T01:56:51.818580Z"}},"outputs":[{"name":"stdout","text":"Baseline RF →  Acc: 0.9660, AUC: 0.9978\nWeighted RF →  Acc: 0.9670, AUC: 0.9978\n","output_type":"stream"}],"execution_count":63}]}