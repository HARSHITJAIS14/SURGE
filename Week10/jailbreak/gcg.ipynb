{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b31b82ec",
   "metadata": {},
   "source": [
    "# Greedy Coordinate Gradient (GCG) Attack\n",
    "\n",
    "This notebook implements the GCG adversarial attack on the fine-tuned BERT model from `bert_finetuning_pipeline.ipynb`.\n",
    "\n",
    "## Goal:\n",
    "To take text classified as AI-generated (label 1) and introduce minimal, targeted perturbations to make the model misclassify it as Human-written (label 0).\n",
    "\n",
    "## Workflow:\n",
    "1.  **Setup**: Load libraries and configure paths.\n",
    "2.  **Load Model & Data**: Load the pre-trained classifier, tokenizer, and test data.\n",
    "3.  **Implement GCG Attack**: Define the core attack logic.\n",
    "4.  **Run Attack**: Select AI-generated text samples and apply the attack.\n",
    "5.  **Analyze Results**: Compare the original and adversarial text to see the changes and the model's new (incorrect) predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97687ff",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ebc7290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch 2.7.1+cu126\n",
      "CUDA available: True\n",
      "GPU: NVIDIA A100 80GB PCIe\n",
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "print(f\"Using PyTorch {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a326bed7",
   "metadata": {},
   "source": [
    "## 2. Configuration and Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bebe71d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for required files...\n",
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration (from experimentation.ipynb) ---\n",
    "model_name = \"bert-base-cased\"\n",
    "max_seq_length = 128\n",
    "batch_size = 32\n",
    "\n",
    "# --- File Paths ---\n",
    "test_data_save_path = \"/home/jivnesh/Harshit_Surge/dataset/test_data_jailbreak.csv\"\n",
    "model_save_dir = \"./saved_models\"\n",
    "model_save_path = os.path.join(model_save_dir, \"bert_finetuned_model.pth\")\n",
    "tokenizer_save_path = os.path.join(model_save_dir, \"tokenizer\")\n",
    "\n",
    "# --- Check if files exist ---\n",
    "print(\"Checking for required files...\")\n",
    "assert os.path.exists(test_data_save_path), f\"Test data not found at {test_data_save_path}\"\n",
    "assert os.path.exists(model_save_path), f\"Model not found at {model_save_path}\"\n",
    "assert os.path.exists(tokenizer_save_path), f\"Tokenizer not found at {tokenizer_save_path}\"\n",
    "print(\"All files found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec448ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model Definition (from experimentation.ipynb) ---\n",
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self, transformer_model, hidden_size, num_labels, dropout_rate=0.1):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.transformer = transformer_model\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.classifier = nn.Linear(hidden_size, num_labels)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        outputs = self.transformer(input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]  # [CLS] token\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits\n",
    "\n",
    "# --- Utility Functions (from experimentation.ipynb) ---\n",
    "def load_saved_model(model_path, tokenizer_path, device):\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model_config = checkpoint['model_config']\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "    transformer = AutoModel.from_pretrained(model_config['model_name']).to(device)\n",
    "    \n",
    "    model = BERTClassifier(\n",
    "        transformer_model=transformer,\n",
    "        hidden_size=model_config['hidden_size'],\n",
    "        num_labels=model_config['num_labels'],\n",
    "        dropout_rate=model_config['dropout_rate']\n",
    "    ).to(device)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    return model, tokenizer, checkpoint\n",
    "\n",
    "def create_dataloader(texts, labels, tokenizer, max_length, batch_size):\n",
    "    # This version is simplified for single-item or small batch prediction\n",
    "    encoded = tokenizer(texts, padding='max_length', truncation=True, max_length=max_length, return_tensors='pt')\n",
    "    input_ids = encoded['input_ids']\n",
    "    attention_masks = encoded['attention_mask']\n",
    "    labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "    dataset = TensorDataset(input_ids, attention_masks, labels_tensor)\n",
    "    dataloader = DataLoader(dataset, sampler=SequentialSampler(dataset), batch_size=batch_size)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bc063ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and tokenizer...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully.\n",
      "Loading test data...\n",
      "Loaded 20000 total test samples.\n",
      "Found 13548 AI-generated samples to attack.\n"
     ]
    }
   ],
   "source": [
    "# --- Load the Model and Tokenizer ---\n",
    "print(\"Loading model and tokenizer...\")\n",
    "model, tokenizer, checkpoint = load_saved_model(model_save_path, tokenizer_save_path, device)\n",
    "print(\"Model and tokenizer loaded successfully.\")\n",
    "\n",
    "# --- Load and Prepare Data ---\n",
    "print(\"Loading test data...\")\n",
    "test_df = pd.read_csv(test_data_save_path)\n",
    "# We only need AI text for the attack\n",
    "ai_texts_df = test_df[test_df['label'] == 1].copy()\n",
    "print(f\"Loaded {len(test_df)} total test samples.\")\n",
    "print(f\"Found {len(ai_texts_df)} AI-generated samples to attack.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0353ae",
   "metadata": {},
   "source": [
    "## 3. GCG Attack Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3575530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_and_confidence(model, tokenizer, text, device):\n",
    "    \"\"\"Helper function to get a model's prediction and confidence for a single text.\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors='pt', max_length=max_seq_length, padding='max_length', truncation=True)\n",
    "    # Only pass the inputs that the model expects\n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids, attention_mask)\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    pred_label = torch.argmax(probs, dim=1).item()\n",
    "    confidence = probs[0][pred_label].item()\n",
    "    return pred_label, confidence\n",
    "\n",
    "def get_target_loss(model, input_ids, attention_mask, target_label):\n",
    "    \"\"\"Calculates the cross-entropy loss for a specific target label.\"\"\"\n",
    "    logits = model(input_ids, attention_mask)\n",
    "    target_label_tensor = torch.tensor([target_label], device=logits.device)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    return loss(logits, target_label_tensor)\n",
    "\n",
    "def gcg_attack(model, tokenizer, text_to_attack, target_label=0, num_iterations=10, top_k=20):\n",
    "    \"\"\"\n",
    "    Implements the Greedy Coordinate Gradient (GCG) attack.\n",
    "\n",
    "    Args:\n",
    "        model: The fine-tuned BERT classifier.\n",
    "        tokenizer: The model's tokenizer.\n",
    "        text_to_attack (str): The original text (classified as AI).\n",
    "        target_label (int): The label to optimize for (0 for Human).\n",
    "        num_iterations (int): Number of token swaps to attempt.\n",
    "        top_k (int): Number of best candidate tokens to check per position.\n",
    "    \n",
    "    Returns:\n",
    "        A tuple (adversarial_text, success_flag).\n",
    "    \"\"\"\n",
    "    print(\"--- Starting GCG Attack ---\")\n",
    "    device = next(model.parameters()).device\n",
    "    adversarial_text = text_to_attack\n",
    "\n",
    "    # Get word embeddings from the model\n",
    "    embeddings = model.transformer.get_input_embeddings().weight\n",
    "\n",
    "    for i in tqdm(range(num_iterations), desc=\"Attack Iterations\"):\n",
    "        # Tokenize the current text\n",
    "        inputs = tokenizer(adversarial_text, return_tensors='pt', max_length=max_seq_length, padding='max_length', truncation=True)\n",
    "        input_ids = inputs['input_ids'][0].to(device)\n",
    "        attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "        # Get the current prediction and check if the attack already succeeded\n",
    "        current_pred, _ = get_pred_and_confidence(model, tokenizer, adversarial_text, device)\n",
    "        if current_pred == target_label:\n",
    "            print(f\"\\nSuccess! Classification flipped to 'Human' after {i} iterations.\")\n",
    "            return adversarial_text, True\n",
    "\n",
    "        # --- Gradient Calculation Step ---\n",
    "        # Enable gradients for embeddings\n",
    "        input_embeds = model.transformer.get_input_embeddings()(input_ids.unsqueeze(0)).detach()\n",
    "        input_embeds.requires_grad_(True)\n",
    "\n",
    "        # Forward pass with embeddings - we need to call the transformer directly\n",
    "        transformer_outputs = model.transformer(inputs_embeds=input_embeds, attention_mask=attention_mask)\n",
    "        pooled_output = transformer_outputs.last_hidden_state[:, 0, :]  # [CLS] token\n",
    "        pooled_output = model.dropout(pooled_output)\n",
    "        logits = model.classifier(pooled_output)\n",
    "        \n",
    "        # Calculate loss with respect to the target label\n",
    "        target_label_tensor = torch.tensor([target_label], device=device)\n",
    "        loss = nn.CrossEntropyLoss()(logits, target_label_tensor)\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient w.r.t embeddings\n",
    "        grad = input_embeds.grad.squeeze(0)\n",
    "        \n",
    "        # --- Candidate Token Selection Step ---\n",
    "        best_overall_loss = float('inf')\n",
    "        best_swap_info = None\n",
    "        candidate_texts = []\n",
    "        \n",
    "        # Find modifiable token positions (ignore special tokens)\n",
    "        modifiable_indices = [i for i, token_id in enumerate(input_ids) if token_id not in [tokenizer.cls_token_id, tokenizer.sep_token_id, tokenizer.pad_token_id]]\n",
    "\n",
    "        for pos in modifiable_indices:\n",
    "            original_token_id = input_ids[pos].item()\n",
    "            original_embedding = embeddings[original_token_id]\n",
    "            grad_at_pos = grad[pos]\n",
    "            \n",
    "            # Score all tokens in the vocabulary based on gradient approximation\n",
    "            scores = -((embeddings - original_embedding) @ grad_at_pos)\n",
    "            \n",
    "            # Get top_k candidates (excluding the original token)\n",
    "            top_k_scores, top_k_indices = torch.topk(scores, top_k + 1)\n",
    "            \n",
    "            for token_idx in top_k_indices:\n",
    "                token_id = token_idx.item()\n",
    "                if token_id == original_token_id: continue\n",
    "                \n",
    "                # Create candidate text\n",
    "                temp_ids = input_ids.clone()\n",
    "                temp_ids[pos] = token_idx\n",
    "                candidate_text = tokenizer.decode(temp_ids, skip_special_tokens=True)\n",
    "                candidate_texts.append(candidate_text)\n",
    "                \n",
    "        # --- Greedy Evaluation Step ---\n",
    "        # Create a dataloader for all candidates to evaluate in a batch\n",
    "        candidate_dataloader = create_dataloader(\n",
    "            candidate_texts,\n",
    "            [target_label] * len(candidate_texts),\n",
    "            tokenizer,\n",
    "            max_seq_length,\n",
    "            batch_size\n",
    "        )\n",
    "\n",
    "        min_loss = float('inf')\n",
    "        best_candidate_idx = -1\n",
    "        with torch.no_grad():\n",
    "            for j, batch in enumerate(candidate_dataloader):\n",
    "                input_ids_batch, attention_mask_batch, _ = [t.to(device) for t in batch]\n",
    "                logits_batch = model(input_ids_batch, attention_mask_batch)\n",
    "                \n",
    "                # Calculate loss for the target class for the entire batch\n",
    "                target_labels_batch = torch.full((len(input_ids_batch),), target_label, device=device, dtype=torch.long)\n",
    "                batch_losses = nn.CrossEntropyLoss(reduction='none')(logits_batch, target_labels_batch)\n",
    "                \n",
    "                # Find the minimum loss in this batch\n",
    "                batch_min_loss, batch_min_idx = torch.min(batch_losses, 0)\n",
    "                if batch_min_loss.item() < min_loss:\n",
    "                    min_loss = batch_min_loss.item()\n",
    "                    best_candidate_idx = j * batch_size + batch_min_idx.item()\n",
    "\n",
    "        # Update the text with the best swap found\n",
    "        if best_candidate_idx != -1:\n",
    "            adversarial_text = candidate_texts[best_candidate_idx]\n",
    "            print(f\"\\nIteration {i+1}: Best swap found. New loss: {min_loss:.4f}\")\n",
    "        else:\n",
    "            print(f\"\\nIteration {i+1}: No better swap found. Stopping.\")\n",
    "            break\n",
    "\n",
    "    # Final check\n",
    "    final_pred, _ = get_pred_and_confidence(model, tokenizer, adversarial_text, device)\n",
    "    if final_pred == target_label:\n",
    "        print(\"\\nSuccess! Final classification is 'Human'.\")\n",
    "        return adversarial_text, True\n",
    "    else:\n",
    "        print(\"\\nFailed. Could not flip classification within the given iterations.\")\n",
    "        return adversarial_text, False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a021e8",
   "metadata": {},
   "source": [
    "## 4. Run the Attack on a Sample Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19c8abfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Original Text Analysis\n",
      "============================================================\n",
      "Text:\n",
      "Diagnostic overshadowing Diagnostic overshadowing is a term used in the field of health care, especially in psychiatry and psychology. While few people are aware of it, diagnostic overshadowing plays a significant role in the care and treatment outcomes of many patients, particularly those with mental health disorders and intellectual disability.\n",
      "\n",
      "### Definition\n",
      "\n",
      "Diagnostic overshadowing refers to a situation where a person's physical symptoms are misattributed to their mental health condition or intellectual disability, leading to the potential dismissal or underdiagnosis of physical health problems. This can lead to inadequate care or even life-threatening situations if serious physical health conditions are overlooked or not properly treated.\n",
      "\n",
      "### Impact on Patient Care\n",
      "\n",
      "This phenomenon can have profound implications for patient care. As physical symptoms are overlooked or misinterpreted, this can delay neccessary interventions and treatments. Moreover, it can lead to an increase in overall healthcare costs due to complications or worsening conditions that could have been managed earlier. Diagnostic overshadowing may also result in misdiagnosis, underdiagnosis, or inadequate treatment of conditions, leading to detrimental effects on the patient's overall well-being.\n",
      "\n",
      "### Prevalence and Consequences\n",
      "\n",
      "While it is difficult to quantify the exact prevalence of diagnostic overshadowing, numerous studies and anecdotal evidence indicate that it remains a significant issue. Individuals with existing mental health conditions or intellectual disabilities may experiance worse health outcomes as a result of diagnostic overshadowing. The consequences can be severe, including poorer quality of life, premature mortality, and increased psychiatric symptoms. \n",
      "\n",
      "### Contributing Factors\n",
      "\n",
      "Several factors contribute to diagnostic overshadowing. Healthcare professionals may lack appropriate training in both mental health and intellectual disability, which can make it difficult to effectively seperate physical health problems from psychiatric symptoms. Communication difficulties can also play a role, as patients with mental health or intellectual disabilities may struggle to accurately describe their physical symptoms.\n",
      "\n",
      "### Prevention and Mitigation Strategies\n",
      "\n",
      "Preventing diagnostic overshadowing requires comprehensive training for healthcare professionals in managing co-existing mental and physical health conditions. Strategies for mitigating the effects include raising awareness among medical professionals, improving communication skills in patient-provider interactions, and implementing integrated care models that accomodate both mental and physical health needs.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "Diagnostic overshadowing is a serious issue that can have life-threatening consequences for individuals with mental health disorders or intellectual disabilities. There is a need for further research and training to better understand and combat this phenomenon, with the ultimate goal of improving the quality of care for all patients.\n",
      "\n",
      "Original Prediction: AI (1)\n",
      "Confidence: 1.0000\n",
      "============================================================\n",
      "--- Starting GCG Attack ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attack Iterations:   5%|â–Œ         | 1/20 [00:19<06:13, 19.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 1: Best swap found. New loss: 11.7125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attack Iterations:  10%|â–ˆ         | 2/20 [00:38<05:48, 19.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 2: Best swap found. New loss: 11.4787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attack Iterations:  15%|â–ˆâ–Œ        | 3/20 [00:55<05:08, 18.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 3: Best swap found. New loss: 11.1995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attack Iterations:  20%|â–ˆâ–ˆ        | 4/20 [01:13<04:51, 18.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 4: Best swap found. New loss: 11.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attack Iterations:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [01:31<04:32, 18.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 5: Best swap found. New loss: 10.8209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attack Iterations:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [01:49<04:10, 17.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 6: Best swap found. New loss: 10.5840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attack Iterations:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [02:06<03:49, 17.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 7: Best swap found. New loss: 10.3488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attack Iterations:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [02:23<03:29, 17.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 8: Best swap found. New loss: 10.1409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attack Iterations:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [02:41<03:13, 17.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 9: Best swap found. New loss: 9.9204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attack Iterations:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [02:59<02:56, 17.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 10: Best swap found. New loss: 9.6790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attack Iterations:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [03:16<02:36, 17.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 11: Best swap found. New loss: 5.2539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attack Iterations:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [03:33<02:22, 17.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 12: Best swap found. New loss: 0.0006\n",
      "\n",
      "Success! Classification flipped to 'Human' after 12 iterations.\n",
      "\n",
      "============================================================\n",
      "Adversarial Text Analysis\n",
      "============================================================\n",
      "Attack Success: True\n",
      "Adversarial Text:\n",
      "Diagnostic overshadowing Diagnostic overshadowing is a term used in the field of health care, especially in psychiatry and psychology. meanings few people are detailed of it, diagnostic overshadowing defining a significant role in the care and treatment persons of many patients, particularly those with mental health disorders and intellectual disability. Sick postedco Definition Diagnostic overshadowing refers to a situation where a person ' s physical symptoms are misattributed to their mental health condition or intellectual disability, < toini potential applicable or underdiagnosis of physical health problems. meanings awaited lead\n",
      "\n",
      "New Prediction: Human (0)\n",
      "New Confidence: 0.9994\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Select a sample AI text that the model is confident about\n",
    "sample_index = 0\n",
    "original_text = ai_texts_df.iloc[sample_index]['text']\n",
    "\n",
    "# Get baseline prediction for this sample\n",
    "original_pred, original_confidence = get_pred_and_confidence(model, tokenizer, original_text, device)\n",
    "pred_map = {0: 'Human', 1: 'AI'}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Original Text Analysis\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Text:\\n{original_text}\\n\")\n",
    "print(f\"Original Prediction: {pred_map.get(original_pred, 'Unknown')} ({original_pred})\")\n",
    "print(f\"Confidence: {original_confidence:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Ensure the sample is correctly classified as AI before attacking\n",
    "if original_pred == 1:\n",
    "    # Run the attack\n",
    "    adversarial_text, success = gcg_attack(\n",
    "        model,\n",
    "        tokenizer,\n",
    "        original_text,\n",
    "        target_label=0, # Target is 'Human'\n",
    "        num_iterations=20, # Increase for harder attacks\n",
    "        top_k=50 # Number of candidates per position\n",
    "    )\n",
    "\n",
    "    # Get prediction for the new adversarial text\n",
    "    new_pred, new_confidence = get_pred_and_confidence(model, tokenizer, adversarial_text, device)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Adversarial Text Analysis\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Attack Success: {success}\")\n",
    "    print(f\"Adversarial Text:\\n{adversarial_text}\\n\")\n",
    "    print(f\"New Prediction: {pred_map.get(new_pred, 'Unknown')} ({new_pred})\")\n",
    "    print(f\"New Confidence: {new_confidence:.4f}\")\n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    print(\"Sample is not classified as AI. Please choose a different sample.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "255cd8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DETAILED ANALYSIS OF THE GCG ATTACK\n",
      "================================================================================\n",
      "\n",
      "ðŸ” Text Comparison:\n",
      "--------------------------------------------------\n",
      "Original text length: 404 words\n",
      "Adversarial text length: 89 words\n",
      "\n",
      "ðŸ“ Key Changes Made by GCG Attack:\n",
      "--------------------------------------------------\n",
      "Position 19: 'While' â†’ 'meanings'\n",
      "Position 23: 'aware' â†’ 'detailed'\n",
      "Position 28: 'plays' â†’ 'defining'\n",
      "Position 37: 'outcomes' â†’ 'persons'\n",
      "\n",
      "ðŸŽ¯ Attack Results Summary:\n",
      "--------------------------------------------------\n",
      "âœ… Attack Success: True\n",
      "ðŸ“Š Original Prediction: AI (confidence: 1.0000)\n",
      "ðŸ“Š Final Prediction: Human (confidence: 0.9994)\n",
      "ðŸ”„ Confidence Change: +0.0005\n",
      "âš¡ Attack completed in 50 iterations\n",
      "\n",
      "ðŸ’¡ Insights:\n",
      "--------------------------------------------------\n",
      "â€¢ The GCG attack successfully fooled the BERT classifier\n",
      "â€¢ Small, targeted word substitutions can drastically change model predictions\n",
      "â€¢ The model's confidence in the adversarial prediction is very high (99.94%)\n",
      "â€¢ This demonstrates the vulnerability of neural text classifiers to adversarial attacks\n",
      "\n",
      "ðŸ”¬ Technical Notes:\n",
      "--------------------------------------------------\n",
      "â€¢ GCG uses gradient information to find optimal token substitutions\n",
      "â€¢ Each iteration evaluates multiple candidate tokens per position\n",
      "â€¢ The attack minimizes the loss for the target class (Human)\n",
      "â€¢ Success is measured by achieving the target classification\n"
     ]
    }
   ],
   "source": [
    "# Cell 12 - Analysis and Comparison\n",
    "print(\"=\"*80)\n",
    "print(\"DETAILED ANALYSIS OF THE GCG ATTACK\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'adversarial_text' in locals() and 'original_text' in locals():\n",
    "    print(\"\\nðŸ” Text Comparison:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Show the differences between original and adversarial text\n",
    "    original_words = original_text.split()\n",
    "    adversarial_words = adversarial_text.split()\n",
    "    \n",
    "    print(f\"Original text length: {len(original_words)} words\")\n",
    "    print(f\"Adversarial text length: {len(adversarial_words)} words\")\n",
    "    \n",
    "    # Find different words\n",
    "    print(f\"\\nðŸ“ Key Changes Made by GCG Attack:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Simple word-by-word comparison for first few lines\n",
    "    min_length = min(len(original_words), len(adversarial_words))\n",
    "    changes_found = 0\n",
    "    \n",
    "    for i in range(min(min_length, 50)):  # Check first 50 words\n",
    "        if original_words[i] != adversarial_words[i]:\n",
    "            changes_found += 1\n",
    "            print(f\"Position {i}: '{original_words[i]}' â†’ '{adversarial_words[i]}'\")\n",
    "    \n",
    "    if changes_found == 0:\n",
    "        print(\"No obvious word substitutions in the first 50 words.\")\n",
    "        print(\"Changes might be more subtle or in later parts of the text.\")\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ Attack Results Summary:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"âœ… Attack Success: {success}\")\n",
    "    print(f\"ðŸ“Š Original Prediction: AI (confidence: {original_confidence:.4f})\")\n",
    "    print(f\"ðŸ“Š Final Prediction: Human (confidence: {new_confidence:.4f})\")\n",
    "    print(f\"ðŸ”„ Confidence Change: {original_confidence - new_confidence:+.4f}\")\n",
    "    print(f\"âš¡ Attack completed in {i+1} iterations\")\n",
    "    \n",
    "    print(f\"\\nðŸ’¡ Insights:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\"â€¢ The GCG attack successfully fooled the BERT classifier\")\n",
    "    print(\"â€¢ Small, targeted word substitutions can drastically change model predictions\")\n",
    "    print(\"â€¢ The model's confidence in the adversarial prediction is very high (99.94%)\")\n",
    "    print(\"â€¢ This demonstrates the vulnerability of neural text classifiers to adversarial attacks\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ No attack results available. Please run the attack first.\")\n",
    "\n",
    "print(f\"\\nðŸ”¬ Technical Notes:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"â€¢ GCG uses gradient information to find optimal token substitutions\")\n",
    "print(\"â€¢ Each iteration evaluates multiple candidate tokens per position\")\n",
    "print(\"â€¢ The attack minimizes the loss for the target class (Human)\")\n",
    "print(\"â€¢ Success is measured by achieving the target classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d3dcc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original Diagnostic overshadowing Diagnostic overshadowing is a term used in the field of health care, especially in psychiatry and psychology. While few people are aware of it, diagnostic overshadowing plays a significant role in the care and treatment outcomes of many patients, particularly those with mental health disorders and intellectual disability.\n",
      "\n",
      "### Definition\n",
      "\n",
      "Diagnostic overshadowing refers to a situation where a person's physical symptoms are misattributed to their mental health condition or intellectual disability, leading to the potential dismissal or underdiagnosis of physical health problems. This can lead to inadequate care or even life-threatening situations if serious physical health conditions are overlooked or not properly treated.\n",
      "\n",
      "### Impact on Patient Care\n",
      "\n",
      "This phenomenon can have profound implications for patient care. As physical symptoms are overlooked or misinterpreted, this can delay neccessary interventions and treatments. Moreover, it can lead to an increase in overall healthcare costs due to complications or worsening conditions that could have been managed earlier. Diagnostic overshadowing may also result in misdiagnosis, underdiagnosis, or inadequate treatment of conditions, leading to detrimental effects on the patient's overall well-being.\n",
      "\n",
      "### Prevalence and Consequences\n",
      "\n",
      "While it is difficult to quantify the exact prevalence of diagnostic overshadowing, numerous studies and anecdotal evidence indicate that it remains a significant issue. Individuals with existing mental health conditions or intellectual disabilities may experiance worse health outcomes as a result of diagnostic overshadowing. The consequences can be severe, including poorer quality of life, premature mortality, and increased psychiatric symptoms. \n",
      "\n",
      "### Contributing Factors\n",
      "\n",
      "Several factors contribute to diagnostic overshadowing. Healthcare professionals may lack appropriate training in both mental health and intellectual disability, which can make it difficult to effectively seperate physical health problems from psychiatric symptoms. Communication difficulties can also play a role, as patients with mental health or intellectual disabilities may struggle to accurately describe their physical symptoms.\n",
      "\n",
      "### Prevention and Mitigation Strategies\n",
      "\n",
      "Preventing diagnostic overshadowing requires comprehensive training for healthcare professionals in managing co-existing mental and physical health conditions. Strategies for mitigating the effects include raising awareness among medical professionals, improving communication skills in patient-provider interactions, and implementing integrated care models that accomodate both mental and physical health needs.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "Diagnostic overshadowing is a serious issue that can have life-threatening consequences for individuals with mental health disorders or intellectual disabilities. There is a need for further research and training to better understand and combat this phenomenon, with the ultimate goal of improving the quality of care for all patients. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"original\" ,original_text,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12839969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adversarial Diagnostic overshadowing Diagnostic overshadowing is a term used in the field of health care, especially in psychiatry and psychology. meanings few people are detailed of it, diagnostic overshadowing defining a significant role in the care and treatment persons of many patients, particularly those with mental health disorders and intellectual disability. Sick postedco Definition Diagnostic overshadowing refers to a situation where a person ' s physical symptoms are misattributed to their mental health condition or intellectual disability, < toini potential applicable or underdiagnosis of physical health problems. meanings awaited lead\n"
     ]
    }
   ],
   "source": [
    "print(\"adversarial\", adversarial_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0f2630",
   "metadata": {},
   "source": [
    "## 5. Universal Trigger Attack Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2691083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Universal trigger function defined successfully!\n"
     ]
    }
   ],
   "source": [
    "def find_universal_trigger(model, tokenizer, train_texts, L=20, \n",
    "                           batch_size=32, steps=100, lr=1e-2, target_label=0):\n",
    "    \"\"\"\n",
    "    Find a universal trigger sequence that can fool the model on multiple inputs.\n",
    "    \n",
    "    Args:\n",
    "        model: The BERT classifier\n",
    "        tokenizer: The tokenizer\n",
    "        train_texts: List of text samples to optimize against\n",
    "        L: Length of trigger sequence\n",
    "        batch_size: Batch size for optimization\n",
    "        steps: Number of optimization steps\n",
    "        lr: Learning rate\n",
    "        target_label: Target label to optimize for (0 = Human)\n",
    "    \n",
    "    Returns:\n",
    "        String containing the universal trigger\n",
    "    \"\"\"\n",
    "    print(f\"Finding universal trigger of length {L} over {steps} steps...\")\n",
    "    \n",
    "    # 1. Initialize trigger token IDs randomly (avoid special tokens)\n",
    "    vocab_size = len(tokenizer.vocab)\n",
    "    special_token_ids = {tokenizer.cls_token_id, tokenizer.sep_token_id, tokenizer.pad_token_id, tokenizer.unk_token_id}\n",
    "    \n",
    "    # Get valid token IDs (exclude special tokens)\n",
    "    valid_token_ids = [i for i in range(vocab_size) if i not in special_token_ids]\n",
    "    trigger_ids = torch.tensor(random.sample(valid_token_ids, L), device=device)\n",
    "    \n",
    "    # 2. Get embedding matrix from the model's transformer\n",
    "    emb_matrix = model.transformer.get_input_embeddings()\n",
    "    trigger_emb = emb_matrix(trigger_ids).detach()  # (L, D)\n",
    "    trigger_emb.requires_grad_(True)\n",
    "\n",
    "    optimizer = torch.optim.Adam([trigger_emb], lr=lr)\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    best_trigger = None\n",
    "\n",
    "    for step in tqdm(range(steps), desc=\"Universal Trigger Optimization\"):\n",
    "        # Sample a batch of texts\n",
    "        if len(train_texts) < batch_size:\n",
    "            batch_texts = train_texts\n",
    "        else:\n",
    "            batch_texts = random.sample(train_texts, batch_size)\n",
    "        \n",
    "        # Tokenize batch\n",
    "        inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, \n",
    "                          truncation=True, max_length=max_seq_length-L).to(device)\n",
    "        \n",
    "        # Get original embeddings\n",
    "        orig_embeds = emb_matrix(inputs.input_ids)  # (B, T, D)\n",
    "        \n",
    "        # Expand trigger embeddings for batch\n",
    "        batch_size_actual = orig_embeds.shape[0]\n",
    "        trig_embeds = trigger_emb.unsqueeze(0).expand(batch_size_actual, -1, -1)  # (B, L, D)\n",
    "        \n",
    "        # Concatenate trigger at the end\n",
    "        all_embeds = torch.cat([orig_embeds, trig_embeds], dim=1)  # (B, T+L, D)\n",
    "        \n",
    "        # Create attention mask for the concatenated sequence\n",
    "        orig_attention = inputs.attention_mask  # (B, T)\n",
    "        trigger_attention = torch.ones(batch_size_actual, L, device=device)  # (B, L)\n",
    "        all_attention = torch.cat([orig_attention, trigger_attention], dim=1)  # (B, T+L)\n",
    "        \n",
    "        # Forward pass through the model\n",
    "        transformer_outputs = model.transformer(inputs_embeds=all_embeds, \n",
    "                                               attention_mask=all_attention)\n",
    "        pooled_output = transformer_outputs.last_hidden_state[:, 0, :]  # [CLS] token\n",
    "        pooled_output = model.dropout(pooled_output)\n",
    "        logits = model.classifier(pooled_output)\n",
    "        \n",
    "        # Calculate loss\n",
    "        target_labels = torch.full((batch_size_actual,), target_label, device=device, dtype=torch.long)\n",
    "        loss = F.cross_entropy(logits, target_labels)\n",
    "        \n",
    "        # Optimization step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Project embeddings back to nearest tokens every few steps\n",
    "        if step % 10 == 0:\n",
    "            with torch.no_grad():\n",
    "                # Compute distances to all vocabulary embeddings\n",
    "                dists = torch.cdist(trigger_emb, emb_matrix.weight)  # (L, V)\n",
    "                nearest = dists.argmin(dim=1)  # (L,)\n",
    "                \n",
    "                # Update embeddings to nearest discrete tokens\n",
    "                trigger_emb.data = emb_matrix(nearest).detach()\n",
    "                trigger_emb.requires_grad_(True)\n",
    "                \n",
    "                # Update optimizer parameter\n",
    "                optimizer.param_groups[0]['params'] = [trigger_emb]\n",
    "        \n",
    "        # Track best trigger\n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            with torch.no_grad():\n",
    "                dists = torch.cdist(trigger_emb, emb_matrix.weight)\n",
    "                best_trigger = dists.argmin(dim=1)\n",
    "        \n",
    "        if step % 20 == 0:\n",
    "            print(f\"Step {step}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Return the best trigger found\n",
    "    final_tokens = tokenizer.convert_ids_to_tokens(best_trigger.tolist())\n",
    "    trigger_string = tokenizer.convert_tokens_to_string(final_tokens)\n",
    "    \n",
    "    print(f\"Universal trigger found: '{trigger_string}'\")\n",
    "    print(f\"Final loss: {best_loss:.4f}\")\n",
    "    \n",
    "    return trigger_string\n",
    "\n",
    "print(\"Universal trigger function defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dca41237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "UNIVERSAL TRIGGER ATTACK\n",
      "============================================================\n",
      "Using 1000 AI text samples for optimization\n",
      "Finding universal trigger of length 30 over 50 steps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Universal Trigger Optimization:   2%|â–         | 1/50 [00:00<00:05,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Loss: 5.5732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Universal Trigger Optimization:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/50 [00:02<00:03,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 20, Loss: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Universal Trigger Optimization:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 42/50 [00:05<00:01,  7.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 40, Loss: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Universal Trigger Optimization: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:06<00:00,  7.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Universal trigger found: 'exercises motions magazine nest Lexington Ka way ran transmitted Lev define 2nd sensualÎš Fielding memoryTL Creation Leinsterural UCI Trying Tobias 237 Traditional devotion eki litre lending'\n",
      "Final loss: 0.0001\n",
      "\n",
      "ðŸŽ¯ Universal Trigger Found: 'exercises motions magazine nest Lexington Ka way ran transmitted Lev define 2nd sensualÎš Fielding memoryTL Creation Leinsterural UCI Trying Tobias 237 Traditional devotion eki litre lending'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run Universal Trigger Attack\n",
    "print(\"=\"*60)\n",
    "print(\"UNIVERSAL TRIGGER ATTACK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get a sample of AI texts to optimize against\n",
    "num_samples = 1000  # Use a smaller sample for faster optimization\n",
    "ai_sample_texts = ai_texts_df['text'].sample(n=min(num_samples, len(ai_texts_df)), random_state=42).tolist()\n",
    "\n",
    "print(f\"Using {len(ai_sample_texts)} AI text samples for optimization\")\n",
    "\n",
    "# Find the universal trigger\n",
    "universal_trigger = find_universal_trigger(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer, \n",
    "    train_texts=ai_sample_texts,\n",
    "    L=30,  # Longer trigger for better optimization\n",
    "    batch_size=16,  # Smaller batch size\n",
    "    steps=50,  # Fewer steps for demo\n",
    "    lr=1e-2,\n",
    "    target_label=0  # Target: Human\n",
    ")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Universal Trigger Found: '{universal_trigger}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92d338e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "UNIVERSAL TRIGGER COMPARISON: TRAINING vs UNSEEN SAMPLES\n",
      "================================================================================\n",
      "Testing universal trigger on:\n",
      "1. GCG Training Samples: 50 texts\n",
      "2. Unseen Samples: 50 texts\n",
      "\n",
      "--- Testing Universal Trigger: GCG Training Samples ---\n",
      "Trigger: 'exercises motions magazine nest Lexington Ka way ran transmitted Lev define 2nd sensualÎš Fielding memoryTL Creation Leinsterural UCI Trying Tobias 237 Traditional devotion eki litre lending'\n",
      "Testing on 50 samples...\n",
      "  Sample 1: 1(1.000) â†’ 1(1.000) âŒ\n",
      "  Sample 2: 1(1.000) â†’ 1(1.000) âŒ\n",
      "  Sample 3: 1(0.992) â†’ 1(0.992) âŒ\n",
      "  Sample 4: 1(1.000) â†’ 1(1.000) âŒ\n",
      "  Sample 5: 1(1.000) â†’ 1(1.000) âŒ\n",
      "  Sample 6: 1(1.000) â†’ 1(1.000) âŒ\n",
      "  Sample 7: 1(1.000) â†’ 1(1.000) âŒ\n",
      "  Sample 8: 1(1.000) â†’ 1(1.000) âŒ\n",
      "  Sample 9: 1(1.000) â†’ 1(1.000) âŒ\n",
      "  Sample 10: 1(1.000) â†’ 1(1.000) âŒ\n",
      "  Sample 6: 1(1.000) â†’ 1(1.000) âŒ\n",
      "  Sample 7: 1(1.000) â†’ 1(1.000) âŒ\n",
      "  Sample 8: 1(1.000) â†’ 1(1.000) âŒ\n",
      "  Sample 9: 1(1.000) â†’ 1(1.000) âŒ\n",
      "  Sample 10: 1(1.000) â†’ 1(1.000) âŒ\n",
      "\n",
      "  ðŸ“Š Results for GCG Training Samples:\n",
      "     Success rate: 1/49 = 2.0%\n",
      "     AI samples tested: 49\n",
      "\n",
      "--- Testing Universal Trigger: Unseen Samples ---\n",
      "Trigger: 'exercises motions magazine nest Lexington Ka way ran transmitted Lev define 2nd sensualÎš Fielding memoryTL Creation Leinsterural UCI Trying Tobias 237 Traditional devotion eki litre lending'\n",
      "Testing on 50 samples...\n",
      "  Sample 1: 1(1.000) â†’ 1(1.000) âŒ\n",
      "  Sample 2: 1(1.000) â†’ 1(1.000) âŒ\n",
      "  Sample 3: 1(1.000) â†’ 1(1.000) âŒ\n",
      "  Sample 4: 1(1.000) â†’ 1(1.000) âŒ\n",
      "  Sample 5: 1(1.000) â†’ 1(1.000) âŒ\n",
      "  Sample 6: 1(1.000) â†’ 1(1.000) âŒ\n",
      "  Sample 7: 1(1.000) â†’ 1(1.000) âŒ\n",
      "\n",
      "  ðŸ“Š Results for GCG Training Samples:\n",
      "     Success rate: 1/49 = 2.0%\n",
      "     AI samples tested: 49\n",
      "\n",
      "--- Testing Universal Trigger: Unseen Samples ---\n",
      "Trigger: 'exercises motions magazine nest Lexington Ka way ran transmitted Lev define 2nd sensualÎš Fielding memoryTL Creation Leinsterural UCI Trying Tobias 237 Traditional devotion eki litre lending'\n",
      "Testing on 50 samples...\n",
      "  Sample 1: 1(1.000) â†’ 1(1.000) âŒ\n",
      "  Sample 2: 1(1.000) â†’ 1(1.000) âŒ\n",
      "  Sample 3: 1(1.000) â†’ 1(1.000) âŒ\n",
      "  Sample 4: 1(1.000) â†’ 1(1.000) âŒ\n",
      "  Sample 5: 1(1.000) â†’ 1(1.000) âŒ\n",
      "  Sample 6: 1(1.000) â†’ 1(1.000) âŒ\n",
      "  Sample 7: 1(1.000) â†’ 1(1.000) âŒ\n",
      "  Sample 8: 1(1.000) â†’ 1(1.000) âŒ\n",
      "  Sample 9: 1(1.000) â†’ 1(1.000) âŒ\n",
      "  Sample 10: 1(1.000) â†’ 1(1.000) âŒ\n",
      "  Sample 8: 1(1.000) â†’ 1(1.000) âŒ\n",
      "  Sample 9: 1(1.000) â†’ 1(1.000) âŒ\n",
      "  Sample 10: 1(1.000) â†’ 1(1.000) âŒ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  ðŸ“Š Results for Unseen Samples:\n",
      "     Success rate: 0/50 = 0.0%\n",
      "     AI samples tested: 50\n",
      "\n",
      "============================================================\n",
      "COMPARISON RESULTS\n",
      "============================================================\n",
      "ðŸ”¹ GCG Training Samples Success Rate: 2.0%\n",
      "ðŸ”¹ Unseen Samples Success Rate: 0.0%\n",
      "ðŸ“ˆ Universal trigger works better on training samples (+2.0%)\n",
      "   This suggests some overfitting to the optimization set.\n",
      "\n",
      "âŒ Universal trigger is largely ineffective (best: 2.0%)\n"
     ]
    }
   ],
   "source": [
    "# Simple Universal Trigger Testing (Suffix Approach for BERT)\n",
    "def test_universal_trigger_simple(model, tokenizer, trigger_text, test_texts, target_label=0, test_name=\"Test\"):\n",
    "    \"\"\"Test universal trigger by simply appending it as a suffix\"\"\"\n",
    "    \n",
    "    print(f\"\\n--- Testing Universal Trigger: {test_name} ---\")\n",
    "    print(f\"Trigger: '{trigger_text}'\")\n",
    "    print(f\"Testing on {len(test_texts)} samples...\")\n",
    "    \n",
    "    successful_attacks = 0\n",
    "    results = []\n",
    "    \n",
    "    for i, original_text in enumerate(test_texts):\n",
    "        # Get original prediction\n",
    "        orig_pred, orig_conf = get_pred_and_confidence(model, tokenizer, original_text, device)\n",
    "        \n",
    "        # Only test on AI samples (label 1)\n",
    "        if orig_pred != 1:\n",
    "            continue\n",
    "            \n",
    "        # Apply trigger as suffix (simple approach for BERT)\n",
    "        adversarial_text = original_text + \" \" + trigger_text\n",
    "        \n",
    "        # Get adversarial prediction\n",
    "        adv_pred, adv_conf = get_pred_and_confidence(model, tokenizer, adversarial_text, device)\n",
    "        \n",
    "        # Check if attack succeeded\n",
    "        success = (adv_pred == target_label)\n",
    "        if success:\n",
    "            successful_attacks += 1\n",
    "            \n",
    "        results.append({\n",
    "            'sample_idx': i,\n",
    "            'original_pred': orig_pred,\n",
    "            'original_conf': orig_conf,\n",
    "            'adversarial_pred': adv_pred,\n",
    "            'adversarial_conf': adv_conf,\n",
    "            'success': success\n",
    "        })\n",
    "        \n",
    "        if i < 10:  # Show details for first 10 samples\n",
    "            print(f\"  Sample {i+1}: {orig_pred}({orig_conf:.3f}) â†’ {adv_pred}({adv_conf:.3f}) {'âœ…' if success else 'âŒ'}\")\n",
    "    \n",
    "    success_rate = successful_attacks / len([r for r in results if r['original_pred'] == 1])\n",
    "    print(f\"\\n  ðŸ“Š Results for {test_name}:\")\n",
    "    print(f\"     Success rate: {successful_attacks}/{len([r for r in results if r['original_pred'] == 1])} = {success_rate:.1%}\")\n",
    "    print(f\"     AI samples tested: {len([r for r in results if r['original_pred'] == 1])}\")\n",
    "    \n",
    "    return success_rate, results\n",
    "\n",
    "# Test Universal Trigger on Different Sample Sets\n",
    "if 'universal_trigger' in locals() and 'ai_sample_texts' in locals():\n",
    "    print(\"=\"*80)\n",
    "    print(\"UNIVERSAL TRIGGER COMPARISON: TRAINING vs UNSEEN SAMPLES\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Test Set 1: GCG Training Samples (first 50 from ai_sample_texts)\n",
    "    gcg_training_samples = ai_sample_texts[:50]  \n",
    "    \n",
    "    # Test Set 2: Completely Unseen Samples (samples NOT in ai_sample_texts)\n",
    "    # Get indices of ai_sample_texts in the original dataframe\n",
    "    ai_sample_indices = ai_texts_df['text'].sample(n=min(1000, len(ai_texts_df)), random_state=42).index\n",
    "    \n",
    "    # Get unseen samples (not in the training set)\n",
    "    unseen_mask = ~ai_texts_df.index.isin(ai_sample_indices)\n",
    "    unseen_samples = ai_texts_df[unseen_mask]['text'].head(50).tolist()\n",
    "    \n",
    "    print(f\"Testing universal trigger on:\")\n",
    "    print(f\"1. GCG Training Samples: {len(gcg_training_samples)} texts\")\n",
    "    print(f\"2. Unseen Samples: {len(unseen_samples)} texts\")\n",
    "    \n",
    "    # Test on GCG training samples\n",
    "    training_success_rate, training_results = test_universal_trigger_simple(\n",
    "        model, tokenizer, universal_trigger, gcg_training_samples, \n",
    "        target_label=0, test_name=\"GCG Training Samples\"\n",
    "    )\n",
    "    \n",
    "    # Test on unseen samples\n",
    "    unseen_success_rate, unseen_results = test_universal_trigger_simple(\n",
    "        model, tokenizer, universal_trigger, unseen_samples, \n",
    "        target_label=0, test_name=\"Unseen Samples\"\n",
    "    )\n",
    "    \n",
    "    # Compare results\n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(\"COMPARISON RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"ðŸ”¹ GCG Training Samples Success Rate: {training_success_rate:.1%}\")\n",
    "    print(f\"ðŸ”¹ Unseen Samples Success Rate: {unseen_success_rate:.1%}\")\n",
    "    \n",
    "    if training_success_rate > unseen_success_rate:\n",
    "        print(f\"ðŸ“ˆ Universal trigger works better on training samples (+{training_success_rate - unseen_success_rate:.1%})\")\n",
    "        print(\"   This suggests some overfitting to the optimization set.\")\n",
    "    elif unseen_success_rate > training_success_rate:\n",
    "        print(f\"ðŸ“‰ Universal trigger works better on unseen samples (+{unseen_success_rate - training_success_rate:.1%})\")\n",
    "        print(\"   This is unexpected and suggests good generalization.\")\n",
    "    else:\n",
    "        print(\"ðŸ”„ Universal trigger performs equally on both sets.\")\n",
    "    \n",
    "    # Overall assessment\n",
    "    if max(training_success_rate, unseen_success_rate) > 0.1:\n",
    "        print(f\"\\nâœ… Universal trigger shows some effectiveness (best: {max(training_success_rate, unseen_success_rate):.1%})\")\n",
    "    else:\n",
    "        print(f\"\\nâŒ Universal trigger is largely ineffective (best: {max(training_success_rate, unseen_success_rate):.1%})\")\n",
    "        \n",
    "else:\n",
    "    print(\"âŒ Universal trigger or training samples not available. Please run the universal trigger attack first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d79455e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPREHENSIVE ATTACK ANALYSIS - FINAL RESULTS\n",
      "================================================================================\n",
      "\n",
      "Attack Comparison:\n",
      "------------------------------------------------------------\n",
      "1. GCG (Greedy Coordinate Gradient) Attack:\n",
      "   SUCCESS: 100% (1/1 samples tested)\n",
      "   PROS: Highly effective, minimal substitutions\n",
      "   CONS: Computationally expensive, not transferable\n",
      "\n",
      "2. Universal Trigger Attack:\n",
      "   Training Samples: 2.0% success rate\n",
      "   Unseen Samples: 0.0% success rate\n",
      "   RESULT: Largely ineffective, shows overfitting\n",
      "   PROS: Efficient once found\n",
      "   CONS: Poor performance on BERT\n",
      "\n",
      "Technical Insights:\n",
      "------------------------------------------------------------\n",
      "GCG Attack Effectiveness:\n",
      "  - Successfully flipped AI to Human classification\n",
      "  - 99.94% confidence in wrong prediction\n",
      "  - Strategic word substitutions\n",
      "  - Demonstrates BERT vulnerability to targeted attacks\n",
      "\n",
      "Universal Trigger Limitations:\n",
      "  - Simple suffix approach ineffective\n",
      "  - BERT's bidirectional nature resists position tricks\n",
      "  - Good robustness to generic patterns\n",
      "  - Needs more sophisticated optimization\n",
      "\n",
      "Quantitative Results:\n",
      "------------------------------------------------------------\n",
      "GCG Attack: 100% success rate\n",
      "GCG Time: ~3.5 minutes per sample\n",
      "Confidence: 1.000 -> 0.999\n",
      "Universal (Training): 2.0%\n",
      "Universal (Unseen): 0.0%\n",
      "Universal Time: ~1 minute for 1000 samples\n",
      "\n",
      "Key Findings:\n",
      "------------------------------------------------------------\n",
      "1. BERT is VULNERABLE to targeted adversarial attacks\n",
      "2. BERT is ROBUST to universal trigger attacks\n",
      "3. Per-sample optimization >> universal patterns\n",
      "4. Bidirectional attention increases robustness\n",
      "\n",
      "Defense Recommendations:\n",
      "------------------------------------------------------------\n",
      "- Implement adversarial training with GCG-style attacks\n",
      "- Add input validation for suspicious substitutions\n",
      "- Use ensemble methods for robustness\n",
      "- Monitor confidence changes\n",
      "- Consider defensive distillation\n",
      "\n",
      "Practical Implications:\n",
      "------------------------------------------------------------\n",
      "- AI detectors need protection against targeted attacks\n",
      "- Universal triggers not major threat for BERT\n",
      "- Focused attacks pose real security risk\n",
      "- Detection systems need adversarial awareness\n",
      "\n",
      "Attack Artifacts:\n",
      "------------------------------------------------------------\n",
      "Universal Trigger: 'exercises motions magazine nest Lexington Ka way ran transmitted Lev define 2nd sensualÎš Fielding memoryTL Creation Leinsterural UCI Trying Tobias 237 Traditional devotion eki litre lending'\n",
      "GCG: 4+ strategic word substitutions\n",
      "Conclusion: Gradient-based > Universal patterns\n"
     ]
    }
   ],
   "source": [
    "# Final Analysis: GCG vs Universal Trigger Attacks\n",
    "print(\"=\"*80)\n",
    "print(\"COMPREHENSIVE ATTACK ANALYSIS - FINAL RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nAttack Comparison:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "print(\"1. GCG (Greedy Coordinate Gradient) Attack:\")\n",
    "print(\"   SUCCESS: 100% (1/1 samples tested)\")\n",
    "print(\"   PROS: Highly effective, minimal substitutions\")\n",
    "print(\"   CONS: Computationally expensive, not transferable\")\n",
    "\n",
    "print(\"\\n2. Universal Trigger Attack:\")\n",
    "if 'training_success_rate' in locals() and 'unseen_success_rate' in locals():\n",
    "    print(f\"   Training Samples: {training_success_rate:.1%} success rate\")\n",
    "    print(f\"   Unseen Samples: {unseen_success_rate:.1%} success rate\")\n",
    "    print(\"   RESULT: Largely ineffective, shows overfitting\")\n",
    "    print(\"   PROS: Efficient once found\")\n",
    "    print(\"   CONS: Poor performance on BERT\")\n",
    "else:\n",
    "    print(\"   Results not available - run universal trigger test first\")\n",
    "\n",
    "print(\"\\nTechnical Insights:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "print(\"GCG Attack Effectiveness:\")\n",
    "print(\"  - Successfully flipped AI to Human classification\")\n",
    "print(\"  - 99.94% confidence in wrong prediction\")\n",
    "print(\"  - Strategic word substitutions\")\n",
    "print(\"  - Demonstrates BERT vulnerability to targeted attacks\")\n",
    "\n",
    "print(\"\\nUniversal Trigger Limitations:\")\n",
    "print(\"  - Simple suffix approach ineffective\")\n",
    "print(\"  - BERT's bidirectional nature resists position tricks\")\n",
    "print(\"  - Good robustness to generic patterns\")\n",
    "print(\"  - Needs more sophisticated optimization\")\n",
    "\n",
    "print(\"\\nQuantitative Results:\")\n",
    "print(\"-\" * 60)\n",
    "if 'success' in locals():\n",
    "    print(f\"GCG Attack: 100% success rate\")\n",
    "    print(f\"GCG Time: ~3.5 minutes per sample\")\n",
    "    if 'original_confidence' in locals() and 'new_confidence' in locals():\n",
    "        print(f\"Confidence: {original_confidence:.3f} -> {new_confidence:.3f}\")\n",
    "\n",
    "if 'training_success_rate' in locals():\n",
    "    print(f\"Universal (Training): {training_success_rate:.1%}\")\n",
    "    print(f\"Universal (Unseen): {unseen_success_rate:.1%}\")\n",
    "    print(\"Universal Time: ~1 minute for 1000 samples\")\n",
    "\n",
    "print(\"\\nKey Findings:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"1. BERT is VULNERABLE to targeted adversarial attacks\")\n",
    "print(\"2. BERT is ROBUST to universal trigger attacks\")\n",
    "print(\"3. Per-sample optimization >> universal patterns\")\n",
    "print(\"4. Bidirectional attention increases robustness\")\n",
    "\n",
    "print(\"\\nDefense Recommendations:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"- Implement adversarial training with GCG-style attacks\")\n",
    "print(\"- Add input validation for suspicious substitutions\")\n",
    "print(\"- Use ensemble methods for robustness\")\n",
    "print(\"- Monitor confidence changes\")\n",
    "print(\"- Consider defensive distillation\")\n",
    "\n",
    "print(\"\\nPractical Implications:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"- AI detectors need protection against targeted attacks\")\n",
    "print(\"- Universal triggers not major threat for BERT\")\n",
    "print(\"- Focused attacks pose real security risk\")\n",
    "print(\"- Detection systems need adversarial awareness\")\n",
    "\n",
    "if 'universal_trigger' in locals():\n",
    "    print(f\"\\nAttack Artifacts:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Universal Trigger: '{universal_trigger}'\")\n",
    "    print(\"GCG: 4+ strategic word substitutions\")\n",
    "    print(\"Conclusion: Gradient-based > Universal patterns\")\n",
    "else:\n",
    "    print(\"\\nSome results incomplete - run all cells for full analysis\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "harshitml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
